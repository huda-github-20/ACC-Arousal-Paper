{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pupil_classv2 as pc\n",
    "import math\n",
    "from statistics import mean\n",
    "import csv\n",
    "from timestamps import new_timestamps\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from helper import *\n",
    "import tdt\n",
    "from scipy.signal import find_peaks, peak_widths,resample,correlate, correlation_lags,peak_prominences,resample,butter, lfilter, freqz,medfilt,hilbert\n",
    "from scipy.stats import pearsonr,wilcoxon,mannwhitneyu,kruskal\n",
    "import os\n",
    "from fp_helper import *\n",
    "from matplotlib import rcParams\n",
    "import cv2\n",
    "from scipy.stats import ttest_ind,ttest_rel,zscore\n",
    "from sklearn.linear_model import Ridge,RidgeCV\n",
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "from random import randint\n",
    "from scipy.ndimage import median_filter\n",
    "import scikit_posthocs as sp\n",
    "import statsmodels.api as sm \n",
    "from statsmodels.formula.api import ols \n",
    "\n",
    "\n",
    "params = {\n",
    "        \"font.family\" : \"Arial\",\n",
    "        'pdf.fonttype' : 42,\n",
    "        'axes.labelsize': 10,\n",
    "        'axes.titlesize': 11,\n",
    "        'axes.linewidth': 0.5,\n",
    "        'xtick.labelsize':9,\n",
    "        'xtick.major.width':0.5,\n",
    "        'ytick.major.width':0.5,\n",
    "        'ytick.labelsize':9,\n",
    "        'axes.spines.top':False,\n",
    "        'axes.spines.right':False\n",
    "         }\n",
    "rcParams['figure.figsize'] = 21.7,8.27\n",
    "rcParams.update(params)\n",
    "def format_ax(ax,xlim,ylim,xspace,yspace):\n",
    "   \n",
    "    ax.set_xticks(np.arange(xlim[0],xlim[1]+ xspace,xspace))\n",
    "    ax.set_yticks(np.arange(ylim[0],ylim[1]+ yspace,yspace))\n",
    "\n",
    "    ax.set(ylim=(ylim[0], ylim[1]))\n",
    "    ax.set(xlim=(xlim[0], xlim[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###low pass filter pupil\n",
    "def filter_pupil(pupil,order = 1,cutoff = 1,fs = 20):\n",
    "    def butter_lowpass(cutoff, fs, order=5):\n",
    "        return butter(order, cutoff, fs=fs, btype='low', analog=False)\n",
    "\n",
    "    def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "        b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "        y = lfilter(b, a, data)\n",
    "        return y\n",
    "\n",
    "    return butter_lowpass_filter(pupil, cutoff, fs, order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get pupil events for ACC\n",
    "###get events from all sessions\n",
    "\n",
    "def get_acc_events(id,date):\n",
    "    id = id\n",
    "    date = date\n",
    "    face_path = f\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/ethanol_data/{id}/{date}/{date}_{id}_sess_1_FaceProcessed.csv\"\n",
    "    path = f\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/ethanol_data/{id}/{date}/{date}_{id}_sess_1_ProcessedData.csv\"\n",
    "    df = pd.read_csv(path)\n",
    "    pupil = np.array(df[\"Pupil Size\"])\n",
    "    time = np.array(df[\"Time\"])\n",
    "    speed = np.array(df[\"Running Speed\"])\n",
    "    speed[0] = 0\n",
    "    dff = np.array(df[\"dFF\"])\n",
    "    face = np.array(pd.read_csv(face_path)[\"Facial Movement\"])\n",
    "\n",
    "    ###Onset detection alogrithm\n",
    "\n",
    "    \n",
    "    filter = filter_pupil(pupil) ###first apply low pass filter to pupil trace\n",
    "\n",
    "    def groupSequence(x): \n",
    "        it = iter(x) \n",
    "        prev, res = next(it), [] \n",
    "    \n",
    "        while prev is not None: \n",
    "            start = next(it, None) \n",
    "    \n",
    "            if start and start > prev:\n",
    "\n",
    "                res.append(prev) \n",
    "            elif res: \n",
    "                yield list(res + [prev]) \n",
    "                res = [] \n",
    "            prev = start \n",
    "\n",
    "\n",
    "    regions = list(groupSequence(filter))\n",
    "    corrected_regions = [region for region in regions if len(region) >=15 ] ###only include regions that are >750ms\n",
    "    corrected_regions = [region for region in corrected_regions if region[0]<np.median(filter) ] ###only include onsets that occur below z = median\n",
    "\n",
    "    region_ix = [[np.where(filter == val)[0][0] for val in region] for region in corrected_regions] ### get indices for each region\n",
    "\n",
    "\n",
    "    ##join regions that are near eachother\n",
    "    new = []\n",
    "    for i,first in enumerate(region_ix):\n",
    "        if i < len(region_ix)-1:\n",
    "            second = region_ix[i + 1]\n",
    "            end = first[-1]\n",
    "            start = second[0]\n",
    "            if first[0] - region_ix[i - 1][-1]>20:\n",
    "                if start-end<= 20:\n",
    "                    #print(first[0]/20,second[0]/20)\n",
    "                    new.append(first + second)\n",
    "                else:\n",
    "                    new.append(first)\n",
    "    region_ix = new\n",
    "    corrected_regions = [filter[region[0]:region[-1]] for region in region_ix]\n",
    "\n",
    "\n",
    "    new = []\n",
    "    for i,first in enumerate(region_ix):\n",
    "        if i < len(region_ix)-1:\n",
    "            second = region_ix[i + 1]\n",
    "            end = first[-1]\n",
    "            start = second[0]\n",
    "            if first[0] - region_ix[i - 1][-1]>10:\n",
    "                if start-end<= 10:\n",
    "                    #print(first[0]/20,second[0]/20)\n",
    "                    new.append(first + second)\n",
    "                else:\n",
    "                    new.append(first)\n",
    "    region_ix = new\n",
    "    corrected_regions = [filter[region[0]:region[-1]] for region in region_ix]\n",
    "    onsets_ix = [region[0] for region in region_ix]\n",
    "\n",
    "\n",
    "    ###get offsets and durations for pupil event\n",
    "    offset_ix = []\n",
    "    durations = []\n",
    "    for i,(region,index) in enumerate(zip(corrected_regions,region_ix)):\n",
    "        if i < len(region_ix)-1:\n",
    "            start = index[-1] ###end of region\n",
    "            end = region_ix[i+1][0] ### start of next region\n",
    "            onset_y = region[0]\n",
    "            offsets = np.where(filter[start:end] <= onset_y) ###find ix of first point that goes below onset \n",
    "        if len(offsets[0]) == 0: ###if it never goes below onset then use lowest value\n",
    "            offset = start + np.argmin(filter[start:end])\n",
    "        else:\n",
    "            offset = start + offsets[0][0]\n",
    "\n",
    "\n",
    "        offset_ix.append(offset)\n",
    "\n",
    "        durations.append((offset-index[0])/20)\n",
    "\n",
    "    ###handle last pupil event\n",
    "    start = region_ix[-1][-1]\n",
    "    end = 36000\n",
    "    onset_y = corrected_regions[-1][0]\n",
    "    offsets = np.where(filter[start:end] <= onset_y)\n",
    "    if len(offsets[0]) == 0:\n",
    "        offset = end-1\n",
    "    else:\n",
    "        offset = start + np.argmin(filter[start:end])\n",
    "\n",
    "    offset_ix[-1] = offset\n",
    "\n",
    "    durations[-1] = (offset-region_ix[-1][0])/20\n",
    "\n",
    "    ###get pupil event amplitudes\n",
    "    amplitudes = []\n",
    "    amplitudes_ix = []\n",
    "    for on,off in zip(onsets_ix,offset_ix):\n",
    "        #print(on,off)\n",
    "        amplitudes.append(max(filter[on:off])-filter[on])\n",
    "        amplitudes_ix.append(on + np.argmax(filter[on:off]))\n",
    "\n",
    "    ###get pupil event slopes\n",
    "    slopes = []\n",
    "    for region in corrected_regions:\n",
    "        run = len(region)/20\n",
    "        rise = region[-1]-region[0]\n",
    "        slopes.append(rise/run)\n",
    "\n",
    "    ###get dff data\n",
    "    aucs = []\n",
    "    peak_dffs = []\n",
    "    mean_dffs = []\n",
    "    for onset,offset in zip(onsets_ix,offset_ix):\n",
    "        baseline = np.mean(dff[onset-40:onset-10])\n",
    "        peak_dffs.append(max(dff[onset:offset]) - np.mean(dff[onset-30:onset]))\n",
    "        mean_dffs.append(np.mean(dff[onset:offset])- np.mean(dff[onset-20:onset]))\n",
    "\n",
    "    ###create dictionary\n",
    "\n",
    "    events_dict = {\"durations\" :durations,\n",
    "    \"amplitudes\": amplitudes,\n",
    "    \"slopes\" : slopes,\n",
    "    \"onsets\" : onsets_ix,\n",
    "    \"offsets\" : offset_ix,\n",
    "    \"peak_ix\" : amplitudes_ix,\n",
    "    \"ID\" : [id] * len(durations),\n",
    "    \"Date\" : [date] * len(durations),\n",
    "    \"peak_dff\" : peak_dffs,\n",
    "    \"mean_dff\" : mean_dffs,\n",
    "\n",
    "\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame.from_dict(events_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get pupil events\n",
    "###get events from all sessions\n",
    "\n",
    "def get_lc_events(id,date):\n",
    "    id = id\n",
    "    date = date\n",
    "    path = f\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Scripts/Nithik/ACC_Arousal_Paper/LC_data/{id}_{date}_fixed.csv\"\n",
    "    df = pd.read_csv(path)\n",
    "    time = df[\"t\"]\n",
    "    pupil = np.array(zscore(df[\"pupil\"])) ###zscore pupil data\n",
    "\n",
    "\n",
    "    ###Onset detection alogrithm\n",
    "\n",
    "    \n",
    "    filter = filter_pupil(pupil) ###first apply low pass filter to pupil trace\n",
    "\n",
    "    def groupSequence(x): \n",
    "        it = iter(x) \n",
    "        prev, res = next(it), [] \n",
    "    \n",
    "        while prev is not None: \n",
    "            start = next(it, None) \n",
    "    \n",
    "            if start and start > prev:\n",
    "\n",
    "                res.append(prev) \n",
    "            elif res: \n",
    "                yield list(res + [prev]) \n",
    "                res = [] \n",
    "            prev = start \n",
    "\n",
    "\n",
    "    regions = list(groupSequence(filter))\n",
    "    corrected_regions = [region for region in regions if len(region) >=15 ] ###only include regions that are >750ms\n",
    "    corrected_regions = [region for region in corrected_regions if region[0]<np.median(filter) ] ###only include onsets that occur below z = median\n",
    "\n",
    "    region_ix = [[np.where(filter == val)[0][0] for val in region] for region in corrected_regions] ### get indices for each region\n",
    "\n",
    "\n",
    "    ##join regions that are near eachother\n",
    "    new = []\n",
    "    for i,first in enumerate(region_ix):\n",
    "        if i < len(region_ix)-1:\n",
    "            second = region_ix[i + 1]\n",
    "            end = first[-1]\n",
    "            start = second[0]\n",
    "            if first[0] - region_ix[i - 1][-1]>20:\n",
    "                if start-end<= 20:\n",
    "                    #print(first[0]/20,second[0]/20)\n",
    "                    new.append(first + second)\n",
    "                else:\n",
    "                    new.append(first)\n",
    "    region_ix = new\n",
    "    corrected_regions = [filter[region[0]:region[-1]] for region in region_ix]\n",
    "\n",
    "\n",
    "    new = []\n",
    "    for i,first in enumerate(region_ix):\n",
    "        if i < len(region_ix)-1:\n",
    "            second = region_ix[i + 1]\n",
    "            end = first[-1]\n",
    "            start = second[0]\n",
    "            if first[0] - region_ix[i - 1][-1]>10:\n",
    "                if start-end<= 10:\n",
    "                    #print(first[0]/20,second[0]/20)\n",
    "                    new.append(first + second)\n",
    "                else:\n",
    "                    new.append(first)\n",
    "    region_ix = new\n",
    "    corrected_regions = [filter[region[0]:region[-1]] for region in region_ix]\n",
    "    onsets_ix = [region[0] for region in region_ix]\n",
    "\n",
    "\n",
    "    ###get offsets and durations for pupil event\n",
    "    offset_ix = []\n",
    "    durations = []\n",
    "    for i,(region,index) in enumerate(zip(corrected_regions,region_ix)):\n",
    "        if i < len(region_ix)-1:\n",
    "            start = index[-1] ###end of region\n",
    "            end = region_ix[i+1][0] ### start of next region\n",
    "            onset_y = region[0]\n",
    "            offsets = np.where(filter[start:end] <= onset_y) ###find ix of first point that goes below onset \n",
    "        if len(offsets[0]) == 0: ###if it never goes below onset then use lowest value\n",
    "            offset = start + np.argmin(filter[start:end])\n",
    "        else:\n",
    "            offset = start + offsets[0][0]\n",
    "\n",
    "\n",
    "        offset_ix.append(offset)\n",
    "\n",
    "        durations.append((offset-index[0])/20)\n",
    "\n",
    "    ###handle last pupil event\n",
    "    start = region_ix[-1][-1]\n",
    "    end = len(pupil)\n",
    "    onset_y = corrected_regions[-1][0]\n",
    "    offsets = np.where(filter[start:end] <= onset_y)\n",
    "    if len(offsets[0]) == 0:\n",
    "        offset = end-1\n",
    "    else:\n",
    "        offset = start + np.argmin(filter[start:end])\n",
    "\n",
    "    offset_ix[-1] = offset\n",
    "\n",
    "    durations[-1] = (offset-region_ix[-1][0])/20\n",
    "\n",
    "    ###get pupil event amplitudes\n",
    "    amplitudes = []\n",
    "    amplitudes_ix = []\n",
    "    for on,off in zip(onsets_ix,offset_ix):\n",
    "        #print(on,off)\n",
    "        amplitudes.append(max(filter[on:off])-filter[on])\n",
    "        amplitudes_ix.append(on + np.argmax(filter[on:off]))\n",
    "\n",
    "    ###get pupil event slopes\n",
    "    slopes = []\n",
    "    for region in corrected_regions:\n",
    "        run = len(region)/20\n",
    "        rise = region[-1]-region[0]\n",
    "        slopes.append(rise/run)\n",
    "\n",
    "    # ###get dff data\n",
    "    # aucs = []\n",
    "    # peak_dffs = []\n",
    "    # mean_dffs = []\n",
    "    # for onset,offset in zip(onsets_ix,offset_ix):\n",
    "    #     baseline = np.mean(dff[onset-40:onset-10])\n",
    "    #     peak_dffs.append(max(dff[onset:offset]) - np.mean(dff[onset-30:onset]))\n",
    "    #     mean_dffs.append(np.mean(dff[onset:offset])- np.mean(dff[onset-20:onset]))\n",
    "\n",
    "    ###create dictionary\n",
    "\n",
    "    events_dict = {\"durations\" :durations,\n",
    "    \"amplitudes\": amplitudes,\n",
    "    \"slopes\" : slopes,\n",
    "    \"onsets\" : onsets_ix,\n",
    "    \"offsets\" : offset_ix,\n",
    "    \"peak_ix\" : amplitudes_ix,\n",
    "    \"ID\" : [id] * len(durations),\n",
    "    \"Date\" : [date] * len(durations),\n",
    "    #\"peak_dff\" : peak_dffs,\n",
    "    #\"mean_dff\" : mean_dffs,\n",
    "    }\n",
    "    return pd.DataFrame.from_dict(events_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###read in correlation data for ACC\n",
    "###correlation with dff\n",
    "\n",
    "id_date = {\n",
    "  \"004113\":[\"20230808\"],\n",
    "  \"004114\":[\"20230808\",\"20230815\"],\n",
    "  \"004115\":[\"20230804\",\"20230808\",\"20230815\"],\n",
    "  \"004116\":[\"20230804\",\"20230808\",\"20230815\"],\n",
    "  \"004117\":[\"20230804\",\"20230808\",\"20230815\"],\n",
    "  \"004118\":[\"20230804\",\"20230808\",\"20230815\"]\n",
    "}\n",
    "df_list = []\n",
    "\n",
    "\n",
    "for id,dates in id_date.items():\n",
    "    for date in dates:\n",
    "      face_path = f\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/ethanol_data/{id}/{date}/{date}_{id}_sess_1_FaceProcessed.csv\"\n",
    "      path = f\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/ethanol_data/{id}/{date}/{date}_{id}_sess_1_ProcessedData.csv\"\n",
    "      df = pd.read_csv(path)\n",
    "      pupil = np.array(df[\"Pupil Size\"])\n",
    "      time = np.array(df[\"Time\"])\n",
    "      speed =zscore(np.array(df[\"Running Speed\"]))\n",
    "      dff = np.array(df[\"dFF\"])\n",
    "      face = np.array(pd.read_csv(face_path)[\"Facial Movement\"])\n",
    "      df[\"Facial Movement\"] = face\n",
    "\n",
    "      new_dict = {\"R\":pearsonr(dff,pupil)[0], \"type\": \"P-D\", \"ID\" : id, \"Date\": date,\"Region\":\"ACC\"}\n",
    "      df_list.append(new_dict)\n",
    "      # new_dict = {\"R\":pearsonr(dff,speed)[0], \"type\": \"D-S\", \"ID\" : id, \"Date\": date}\n",
    "      # df_list.append(new_dict)\n",
    "      new_dict = {\"R\":pearsonr(dff,face)[0], \"type\": \"F-D\", \"ID\" : id, \"Date\": date,\"Region\":\"ACC\"}\n",
    "      df_list.append(new_dict)\n",
    "\n",
    "acc_r_df = pd.DataFrame.from_dict(df_list)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###read in correlation data for LC\n",
    "\n",
    "\n",
    "\n",
    "id_date = {\n",
    "  \"LC01\":[\"20240419\"],\n",
    "  \"LC02\":[\"20240416\"],\n",
    "  \"LC03\":[\"20240419\"],\n",
    "  \"LC04\":[\"20240416\",\"20240417\"],\n",
    "  \"LC05\":[\"20240513\"],\n",
    "  \"LC06\":[\"20240513\"],\n",
    "}\n",
    "df_list = []\n",
    "\n",
    "\n",
    "for id,dates in id_date.items():\n",
    "    for date in dates:\n",
    "        path = f\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Scripts/Nithik/ACC_Arousal_Paper/LC_data/{id}_{date}_fixed.csv\"\n",
    "        df = pd.read_csv(path)\n",
    "        time = df[\"t\"]\n",
    "        pupil = np.array(zscore(df[\"pupil\"])) ###zscore pupil data\n",
    "        face = np.array(zscore(df[\"mot_whisk\"]))###zscore face data\n",
    "        dff = np.array(zscore(df[\"fp_lc\"])) ###zscore dff data\n",
    "\n",
    "        new_dict = {\"R\":pearsonr(dff,pupil)[0], \"type\": \"P-D\", \"ID\" : id, \"Date\": date,\"Region\":\"LC\"}\n",
    "        df_list.append(new_dict)\n",
    "        # new_dict = {\"R\":pearsonr(dff,speed)[0], \"type\": \"D-S\", \"ID\" : id, \"Date\": date}\n",
    "        # df_list.append(new_dict)\n",
    "        new_dict = {\"R\":pearsonr(dff,face)[0], \"type\": \"F-D\", \"ID\" : id, \"Date\": date,\"Region\":\"LC\"}\n",
    "        df_list.append(new_dict)\n",
    "\n",
    "lc_r_df = pd.DataFrame.from_dict(df_list)\n",
    "\n",
    "###combine into one correlation df\n",
    "r_df = pd.concat([lc_r_df,acc_r_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###LC vs ACC face-dff correlation\n",
    "plt.figure(figsize = (0.6,1.2))\n",
    "g = sns.barplot(data = r_df.groupby([\"ID\",'type',\"Region\"]).mean().reset_index().query(\"type == 'F-D'\"), x = \"Region\", y = \"R\",errorbar=\"se\",fill = None,errwidth= 1)\n",
    "sns.stripplot(data = r_df.groupby([\"ID\",'type',\"Region\"]).mean().reset_index().query(\"type == 'F-D'\"), x = \"Region\", y = \"R\",color = \"black\",alpha = 0.3,s = 4,jitter = 0.1)\n",
    "g.xaxis.label.set_visible(False)\n",
    "g.set_yticks(np.arange(-0.2,1,0.2))\n",
    "g.set(ylim=(0, 0.8))\n",
    "g.set_ylabel(\"F-D Correlation (R)\")\n",
    "#plt.savefig(rf\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Manuscripts/2023-ACCArousal-CurrentBiology/SavedGraphs/F-D_R.pdf\",format =\"pdf\",transparent = True,bbox_inches = \"tight\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###LC vs ACC face-dff correlation stats\n",
    "stat_df = r_df.groupby([\"ID\",'type',\"Region\"]).mean().reset_index().query(\"type == 'F-D'\")\n",
    "group1 = stat_df[stat_df['Region']==\"LC\"]\n",
    "group2 = stat_df[stat_df['Region']==\"ACC\"]\n",
    "mannwhitneyu(group1[\"R\"], group2[\"R\"],nan_policy= \"omit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###LC vs ACC pupil-dff correlation\n",
    "plt.figure(figsize = (0.6,1.2))\n",
    "g = sns.barplot(data = r_df.groupby([\"ID\",'type',\"Region\"]).mean().reset_index().query(\"type == 'P-D'\"), x = \"Region\", y = \"R\",errorbar=\"se\",fill = None,errwidth= 1)\n",
    "sns.stripplot(data = r_df.groupby([\"ID\",'type',\"Region\"]).mean().reset_index().query(\"type == 'P-D'\"), x = \"Region\", y = \"R\",color = \"black\",alpha = 0.3,s = 4,jitter = 0.1)\n",
    "g.xaxis.label.set_visible(False)\n",
    "g.set_yticks(np.arange(-0.2,1,0.2))\n",
    "g.set(ylim=(0, 0.8))\n",
    "g.set_ylabel(\"P-D Correlation (R)\")\n",
    "plt.savefig(rf\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Manuscripts/2023-ACCArousal-CurrentBiology/SavedGraphs/P-D_R.pdf\",format =\"pdf\",transparent = True,bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###LC vs ACC pupil-dff correlation stats\n",
    "stat_df = r_df.groupby([\"ID\",'type',\"Region\"]).mean().reset_index().query(\"type == 'P-D'\")\n",
    "group1 = stat_df[stat_df['Region']==\"LC\"]\n",
    "group2 = stat_df[stat_df['Region']==\"ACC\"]\n",
    "mannwhitneyu(group1[\"R\"], group2[\"R\"],nan_policy= \"omit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###get cross-correlation for ACC\n",
    "pre = 2\n",
    "post =2\n",
    "\n",
    "\n",
    "id_date = {\n",
    "  \"004113\":[\"20230808\"],\n",
    "  \"004114\":[\"20230808\",\"20230815\"],\n",
    "  \"004115\":[\"20230804\",\"20230808\",\"20230815\"],\n",
    "  \"004116\":[\"20230804\",\"20230808\",\"20230815\"],\n",
    "  \"004117\":[\"20230804\",\"20230808\",\"20230815\"],\n",
    "  \"004118\":[\"20230804\",\"20230808\",\"20230815\"]\n",
    "}\n",
    "\n",
    "df_list = []\n",
    "graph_df_list = []\n",
    "for id,dates in id_date.items():\n",
    "    for date in dates:\n",
    "      \n",
    "        events = get_acc_events(id,date)\n",
    "        onsets = [on/20 for on in events[\"onsets\"]] ###get pupil onsets\n",
    "        amplitudes = events[\"amplitudes\"]\n",
    "\n",
    "        face_path = f\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/ethanol_data/{id}/{date}/{date}_{id}_sess_1_FaceProcessed.csv\"\n",
    "        path = f\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/ethanol_data/{id}/{date}/{date}_{id}_sess_1_ProcessedData.csv\"\n",
    "        df = pd.read_csv(path)\n",
    "        pupil = np.array(df[\"Pupil Size\"])\n",
    "        time = np.array(df[\"Time\"])\n",
    "        speed = np.array(df[\"Running Speed\"])\n",
    "        speed = zscore(speed)\n",
    "        dff = np.array(df[\"dFF\"])\n",
    "        face = np.array(pd.read_csv(face_path)[\"Facial Movement\"])\n",
    "\n",
    "        dil_matrix,dil_times = trial_align(onsets,time,pupil,fps = 20,pre = pre, post = post)\n",
    "        face_matrix,face_times = trial_align(onsets,time,face,fps = 20,pre = pre, post = post)\n",
    "        dff_matrix,dff_times = trial_align(onsets,time,dff,fps = 20,pre = pre, post = post)\n",
    "\n",
    "\n",
    "        corr = correlate(np.mean(dil_matrix,axis=0), np.mean(dff_matrix,axis = 0))\n",
    "        lags = correlation_lags(len(np.mean(dil_matrix,axis=0)), len(np.mean(dff_matrix,axis = 0)))\n",
    "        lags = lags/20\n",
    "        corr /= np.max(corr)\n",
    "        i = np.argmax(corr)\n",
    "        delay = lags[i]\n",
    "        lag_dict = {\"Cross-Correlation Delay (s)\" : delay,\"ID\": id, \"date\" : date,\"type\":\"P-D\",\"Region\":\"ACC\"}\n",
    "        df_list.append(lag_dict)\n",
    "\n",
    "        for lag,c in zip(lags,corr):\n",
    "            graph_dict = {\"Lags (s)\": lag,\"Cross-Correlation\": c,\"ID\": id, \"date\" : date,\"type\":\"P-D\"}\n",
    "            graph_df_list.append(graph_dict)\n",
    "        \n",
    "\n",
    "        corr = correlate(np.mean(face_matrix,axis=0), np.mean(dff_matrix,axis = 0))\n",
    "        lags = correlation_lags(len(np.mean(face_matrix,axis=0)), len(np.mean(dff_matrix,axis = 0)))\n",
    "        lags = lags/20\n",
    "        corr /= np.max(corr)\n",
    "        i = np.argmax(corr)\n",
    "        delay = lags[i]\n",
    "        lag_dict = {\"Cross-Correlation Delay (s)\" : delay,\"ID\": id, \"date\" : date,\"type\":\"F-D\",\"Region\":\"ACC\"}\n",
    "        df_list.append(lag_dict)\n",
    "\n",
    "        for lag,c in zip(lags,corr):\n",
    "            graph_dict = {\"Lags (s)\" : lag,\"Cross-Correlation\": c,\"ID\": id, \"date\" : date,\"type\":\"F-D\"}\n",
    "            graph_df_list.append(graph_dict)\n",
    "        \n",
    "acc_lag_df = pd.DataFrame.from_dict(df_list)\n",
    "# graph_df = pd.DataFrame.from_dict(graph_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###get cross-correlation for LC\n",
    "pre = 2\n",
    "post =2\n",
    "\n",
    "\n",
    "id_date = {\n",
    "  \"LC01\":[\"20240419\"],\n",
    "  \"LC02\":[\"20240416\"],\n",
    "  \"LC03\":[\"20240419\"],\n",
    "  \"LC04\":[\"20240416\",\"20240417\"],\n",
    "}\n",
    "\n",
    "df_list = []\n",
    "graph_df_list = []\n",
    "for id,dates in id_date.items():\n",
    "    for date in dates:\n",
    "      \n",
    "        events = get_lc_events(id,date)\n",
    "        onsets = [on/20 for on in events[\"onsets\"]] ###get pupil onsets\n",
    "        amplitudes = events[\"amplitudes\"]\n",
    "\n",
    "        path = f\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Scripts/Nithik/ACC_Arousal_Paper/LC_data/{id}_{date}.csv\"\n",
    "        df = pd.read_csv(path)\n",
    "        time = df[\"t\"]\n",
    "        pupil = np.array(zscore(df[\"pupil\"])) ###zscore pupil data\n",
    "        face = np.array(zscore(df[\"mot_whisk\"]))###zscore face data\n",
    "        dff = np.array(zscore(df[\"fp_lc\"])) ###zscore dff data\n",
    "\n",
    "    \n",
    "        dil_matrix,dil_times = trial_align(onsets,time,pupil,fps = 20,pre = pre, post = post)\n",
    "        face_matrix,face_times = trial_align(onsets,time,face,fps = 20,pre = pre, post = post)\n",
    "        dff_matrix,dff_times = trial_align(onsets,time,dff,fps = 20,pre = pre, post = post)\n",
    "\n",
    "\n",
    "        corr = correlate(np.mean(dil_matrix,axis=0), np.mean(dff_matrix,axis = 0))\n",
    "        lags = correlation_lags(len(np.mean(dil_matrix,axis=0)), len(np.mean(dff_matrix,axis = 0)))\n",
    "        lags = lags/20\n",
    "        corr /= np.max(corr)\n",
    "        i = np.argmax(corr)\n",
    "        delay = lags[i]\n",
    "        lag_dict = {\"Cross-Correlation Delay (s)\" : delay,\"ID\": id, \"date\" : date,\"type\":\"P-D\",\"Region\":\"LC\"}\n",
    "        df_list.append(lag_dict)\n",
    "\n",
    "        for lag,c in zip(lags,corr):\n",
    "            graph_dict = {\"Lags (s)\": lag,\"Cross-Correlation\": c,\"ID\": id, \"date\" : date,\"type\":\"P-D\"}\n",
    "            graph_df_list.append(graph_dict)\n",
    "        \n",
    "\n",
    "        corr = correlate(np.mean(face_matrix,axis=0), np.mean(dff_matrix,axis = 0))\n",
    "        lags = correlation_lags(len(np.mean(face_matrix,axis=0)), len(np.mean(dff_matrix,axis = 0)))\n",
    "        lags = lags/20\n",
    "        corr /= np.max(corr)\n",
    "        i = np.argmax(corr)\n",
    "        delay = lags[i]\n",
    "        lag_dict = {\"Cross-Correlation Delay (s)\" : delay,\"ID\": id, \"date\" : date,\"type\":\"F-D\",\"Region\":\"LC\"}\n",
    "        df_list.append(lag_dict)\n",
    "\n",
    "        for lag,c in zip(lags,corr):\n",
    "            graph_dict = {\"Lags (s)\" : lag,\"Cross-Correlation\": c,\"ID\": id, \"date\" : date,\"type\":\"F-D\"}\n",
    "            graph_df_list.append(graph_dict)\n",
    "        \n",
    "lc_lag_df = pd.DataFrame.from_dict(df_list)\n",
    "# graph_df = pd.DataFrame.from_dict(graph_df_list)\n",
    "\n",
    "###combine into one x-correlation df\n",
    "lag_df = pd.concat([lc_lag_df,acc_lag_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_lag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###LC vs ACC face-dff lag\n",
    "plt.figure(figsize = (0.6,1.2))\n",
    "g = sns.barplot(data = lag_df.groupby([\"ID\",'type',\"Region\"]).mean().reset_index().query(\"type == 'F-D'\"), x = \"Region\", y = \"Cross-Correlation Delay (s)\",errorbar=\"se\",fill = None,errwidth= 1)\n",
    "sns.stripplot(data = lag_df.groupby([\"ID\",'type',\"Region\"]).mean().reset_index().query(\"type == 'F-D'\"), x = \"Region\", y = \"Cross-Correlation Delay (s)\",color = \"black\",alpha = 0.3,s = 4,jitter = 0.1)\n",
    "g.xaxis.label.set_visible(False)\n",
    "g.set_yticks(np.arange(-0.3,0.3,0.1))\n",
    "g.set(ylim=(-0.3, 0.2))\n",
    "g.set_ylabel(\"F-D x-corr delay (s)\")\n",
    "plt.savefig(rf\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Manuscripts/2023-ACCArousal-CurrentBiology/SavedGraphs/F-D_xcorr.pdf\",format =\"pdf\",transparent = True,bbox_inches = \"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###LC vs ACC face-dff lag stats\n",
    "stat_df = lag_df.groupby([\"ID\",'type',\"Region\"]).mean().reset_index().query(\"type == 'F-D'\")\n",
    "group1 = stat_df[stat_df['Region']==\"LC\"]\n",
    "group2 = stat_df[stat_df['Region']==\"ACC\"]\n",
    "ttest_ind(group1[\"Cross-Correlation Delay (s)\"], group2[\"Cross-Correlation Delay (s)\"],nan_policy= \"omit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###LC vs ACC face-dff lag\n",
    "plt.figure(figsize = (0.6,1.2))\n",
    "g = sns.barplot(data = lag_df.groupby([\"ID\",'type',\"Region\"]).mean().reset_index().query(\"type == 'P-D'\"), x = \"Region\", y = \"Cross-Correlation Delay (s)\",errorbar=\"se\",fill = None,errwidth= 1)\n",
    "sns.stripplot(data = lag_df.groupby([\"ID\",'type',\"Region\"]).mean().reset_index().query(\"type == 'P-D'\"), x = \"Region\", y = \"Cross-Correlation Delay (s)\",color = \"black\",alpha = 0.3,s = 4,jitter = 0.1)\n",
    "g.xaxis.label.set_visible(False)\n",
    "g.set_yticks(np.arange(0,3.5,0.5))\n",
    "g.set(ylim=(0, 3))\n",
    "g.set_ylabel(\"P-D x-corr delay (s)\")\n",
    "plt.savefig(rf\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Manuscripts/2023-ACCArousal-CurrentBiology/SavedGraphs/P-D_xcorr.pdf\",format =\"pdf\",transparent = True,bbox_inches = \"tight\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###LC vs ACC face-dff lag stats\n",
    "stat_df = lag_df.groupby([\"ID\",'type',\"Region\"]).mean().reset_index().query(\"type == 'P-D'\")\n",
    "group1 = stat_df[stat_df['Region']==\"LC\"]\n",
    "group2 = stat_df[stat_df['Region']==\"ACC\"]\n",
    "ttest_ind(group1[\"Cross-Correlation Delay (s)\"], group2[\"Cross-Correlation Delay (s)\"],nan_policy= \"omit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###onset aligned ACC activity\n",
    "\n",
    "id_date = {\n",
    "  \"004113\":[\"20230808\"],\n",
    "  \"004114\":[\"20230808\",\"20230815\"],\n",
    "  \"004115\":[\"20230804\",\"20230808\",\"20230815\"],\n",
    "  \"004116\":[\"20230804\",\"20230808\",\"20230815\"],\n",
    "  \"004117\":[\"20230804\",\"20230808\",\"20230815\"],\n",
    "  \"004118\":[\"20230804\",\"20230808\",\"20230815\"]\n",
    "}\n",
    "\n",
    "df_list = []\n",
    "for id,dates in id_date.items():\n",
    "    for date in dates:\n",
    "      \n",
    "        events = get_acc_events(id,date)\n",
    "        onsets = [on/20 for on in events[\"onsets\"]] ###get pupil onsets\n",
    "        onsets_ix = events[\"onsets\"]\n",
    "  \n",
    "        face_path = f\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/ethanol_data/{id}/{date}/{date}_{id}_sess_1_FaceProcessed.csv\"\n",
    "        path = f\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/ethanol_data/{id}/{date}/{date}_{id}_sess_1_ProcessedData.csv\"\n",
    "        df = pd.read_csv(path)\n",
    "        pupil = filter_pupil(np.array(df[\"Pupil Size\"]))\n",
    "        time = np.array(df[\"Time\"])\n",
    "        speed = zscore(np.array(df[\"Running Speed\"]))\n",
    "        dff = np.array(df[\"dFF\"])\n",
    "        face = np.array(pd.read_csv(face_path)[\"Facial Movement\"])\n",
    "\n",
    "        dil_matrix,dil_times = trial_align(onsets,time,pupil,fps = 20,pre = 2, post = 10 )\n",
    "        trial_matrix,trial_times = trial_align(onsets,time,dff,fps = 20,pre = 2, post = 10)\n",
    "        face_matrix,face_times = trial_align(onsets,time,face,fps = 20,pre = 2, post = 10)\n",
    "\n",
    "        for j,trial in enumerate(dil_matrix):\n",
    "            baseline = np.mean(pupil[onsets_ix[j] - 40:onsets_ix[j] - 10])\n",
    "            trial = trial - baseline\n",
    "\n",
    "            for i,Time in enumerate(dil_times):\n",
    "                new_dict = {\"Time from Onset (s)\" : Time, \"trial\" : j, \"value\" : trial[i], \"type\" : \"Pupil\",\"ID\" : id, \"Date\": date}\n",
    "                df_list.append(new_dict)\n",
    "\n",
    "        for j,trial in enumerate(trial_matrix):\n",
    "            baseline = np.mean(dff[onsets_ix[j] - 40:onsets_ix[j] - 10])\n",
    "            trial = trial - baseline\n",
    "         \n",
    "            for i,Time in enumerate(trial_times):\n",
    "                new_dict = {\"Time from Onset (s)\" : Time, \"trial\" : j, \"value\" : trial[i], \"type\" : \"dff\",\"ID\" : id, \"Date\": date}\n",
    "                df_list.append(new_dict)\n",
    "\n",
    "        for j,trial in enumerate(face_matrix):\n",
    "            baseline = np.mean(face[onsets_ix[j] - 40:onsets_ix[j] - 10])\n",
    "            trial = trial - baseline\n",
    "          \n",
    "            for i,Time in enumerate(face_times):\n",
    "                new_dict = {\"Time from Onset (s)\" : Time, \"trial\" : j, \"value\" : trial[i], \"type\" : \"Face\",\"ID\" : id, \"Date\": date}\n",
    "                df_list.append(new_dict)\n",
    "\n",
    "acc_align_df = pd.DataFrame.from_dict(df_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###onset aligned LC activity\n",
    "\n",
    "id_date = {\n",
    "  \"LC01\":[\"20240419\"],\n",
    "  \"LC02\":[\"20240416\"],\n",
    "  \"LC03\":[\"20240419\"],\n",
    "  \"LC04\":[\"20240416\",\"20240417\"],\n",
    "  \"LC05\":[\"20240513\"],\n",
    "  \"LC06\":[\"20240513\"],\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "df_list = []\n",
    "for id,dates in id_date.items():\n",
    "    for date in dates:\n",
    "      \n",
    "        events = get_lc_events(id,date)\n",
    "        onsets = [on/20 for on in events[\"onsets\"]] ###get pupil onsets\n",
    "        onsets_ix = events[\"onsets\"]\n",
    "  \n",
    "        path = f\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Scripts/Nithik/ACC_Arousal_Paper/LC_data/{id}_{date}_fixed.csv\"\n",
    "        df = pd.read_csv(path)\n",
    "        time = df[\"t\"]\n",
    "        pupil = filter_pupil(np.array(zscore(df[\"pupil\"]))) ###zscore pupil data\n",
    "        face = np.array(zscore(df[\"mot_whisk\"]))###zscore face data\n",
    "        dff = np.array(zscore(df[\"fp_lc\"])) ###zscore dff data\n",
    "\n",
    "        dil_matrix,dil_times = trial_align(onsets,time,pupil,fps = 20,pre = 2, post = 10 )\n",
    "        trial_matrix,trial_times = trial_align(onsets,time,dff,fps = 20,pre = 2, post = 10)\n",
    "        face_matrix,face_times = trial_align(onsets,time,face,fps = 20,pre = 2, post = 10)\n",
    "\n",
    "        for j,trial in enumerate(dil_matrix):\n",
    "            baseline = np.mean(pupil[onsets_ix[j] - 40:onsets_ix[j] - 10])\n",
    "            trial = trial - baseline\n",
    "\n",
    "            for i,Time in enumerate(dil_times):\n",
    "                new_dict = {\"Time from Onset (s)\" : Time, \"trial\" : j, \"value\" : trial[i], \"type\" : \"Pupil\",\"ID\" : id, \"Date\": date}\n",
    "                df_list.append(new_dict)\n",
    "\n",
    "        for j,trial in enumerate(trial_matrix):\n",
    "            baseline = np.mean(dff[onsets_ix[j] - 40:onsets_ix[j] - 10])\n",
    "            trial = trial - baseline\n",
    "         \n",
    "            for i,Time in enumerate(trial_times):\n",
    "                new_dict = {\"Time from Onset (s)\" : Time, \"trial\" : j, \"value\" : trial[i], \"type\" : \"dff\",\"ID\" : id, \"Date\": date}\n",
    "                df_list.append(new_dict)\n",
    "\n",
    "        for j,trial in enumerate(face_matrix):\n",
    "            baseline = np.mean(face[onsets_ix[j] - 40:onsets_ix[j] - 10])\n",
    "            trial = trial - baseline\n",
    "          \n",
    "            for i,Time in enumerate(face_times):\n",
    "                new_dict = {\"Time from Onset (s)\" : Time, \"trial\" : j, \"value\" : trial[i], \"type\" : \"Face\",\"ID\" : id, \"Date\": date}\n",
    "                df_list.append(new_dict)\n",
    "\n",
    "lc_align_df = pd.DataFrame.from_dict(df_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###onset aligned ACC trace\n",
    "plt.figure(figsize = (2,1.2))\n",
    "ax = sns.lineplot(data = acc_align_df.groupby([\"ID\",\"Time from Onset (s)\",\"type\"]).mean().reset_index(), x = \"Time from Onset (s)\", y = \"value\", hue = \"type\",errorbar = \"se\",palette= [\"purple\",\"dodgerblue\",\"green\"],legend= None,linewidth = 1)\n",
    "format_ax(ax,(-1,0.5),(-0.5,1),0.5,0.5)\n",
    "ax.set_xlabel(\"Time from dilation onset (s)\")\n",
    "ax.set_ylabel('Z-Score')\n",
    "ax.axvline(0,linestyle = \"dashed\", color = \"black\",linewidth = 0.5)\n",
    "\n",
    "\n",
    "plt.savefig(rf\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Manuscripts/2023-ACCArousal-CurrentBiology/SavedGraphs/ACC_aligned.pdf\",format =\"pdf\",transparent = True,bbox_inches = \"tight\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###onset aligned LC trace\n",
    "plt.figure(figsize = (2,1.2))\n",
    "ax = sns.lineplot(data = lc_align_df.groupby([\"ID\",\"Time from Onset (s)\",\"type\"]).mean().reset_index(), x = \"Time from Onset (s)\", y = \"value\", hue = \"type\",errorbar = \"se\",palette= [\"purple\",\"dodgerblue\",\"green\"],legend= None,linewidth = 1)\n",
    "format_ax(ax,(-1,0.5),(-0.5,2),0.5,0.5)\n",
    "ax.set_xlabel(\"Time from dilation onset (s)\")\n",
    "ax.set_ylabel('Z-Score')\n",
    "ax.axvline(0,linestyle = \"dashed\", color = \"black\",linewidth = 0.5)\n",
    "\n",
    "plt.savefig(rf\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Manuscripts/2023-ACCArousal-CurrentBiology/SavedGraphs/LC_aligned.pdf\",format =\"pdf\",transparent = True,bbox_inches = \"tight\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###hilbert trace for ACC\n",
    "\n",
    "\n",
    "id_date = {\n",
    "  \"004113\":[\"20230808\"],\n",
    "  \"004114\":[\"20230808\",\"20230815\"],\n",
    "  \"004115\":[\"20230804\",\"20230808\",\"20230815\"],\n",
    "  \"004116\":[\"20230804\",\"20230808\",\"20230815\"],\n",
    "  \"004117\":[\"20230804\",\"20230808\",\"20230815\"],\n",
    "  \"004118\":[\"20230804\",\"20230808\",\"20230815\"]\n",
    "}\n",
    "\n",
    "\n",
    "df_list = []\n",
    "for id,dates in id_date.items():\n",
    "    for date in dates:\n",
    "       \n",
    "        face_path = f\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/ethanol_data/{id}/{date}/{date}_{id}_sess_1_FaceProcessed.csv\"\n",
    "        path = f\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/ethanol_data/{id}/{date}/{date}_{id}_sess_1_ProcessedData.csv\"\n",
    "        df = pd.read_csv(path)\n",
    "        pupil = np.array(df[\"Pupil Size\"])\n",
    "        time = np.array(df[\"Time\"])\n",
    "        speed = zscore(np.array(df[\"Running Speed\"]))\n",
    "        dff = np.array(df[\"dFF\"])\n",
    "        face = np.array(pd.read_csv(face_path)[\"Facial Movement\"])\n",
    "        \n",
    "        df = pd.DataFrame(pupil)\n",
    "        df = df.rename(columns= {0:\"pupil\"})\n",
    "        df[\"dff\"] = dff\n",
    "        df[\"face\"] = face\n",
    "        phases = np.angle(hilbert(df[\"pupil\"]))\n",
    "        df[\"phase_bin\"] = pd.cut(phases,128,labels = False)\n",
    "        df[\"ID\"] = id\n",
    "        df[\"Date\"] = date\n",
    "        df[\"Region\"] = \"ACC\"\n",
    "        df_list.append(df)\n",
    "        \n",
    "acc_hilbert_df = pd.concat(df_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###hilbert trace for LC\n",
    "\n",
    "\n",
    "id_date = {\n",
    "  \"LC01\":[\"20240419\"],\n",
    "  \"LC02\":[\"20240416\"],\n",
    "  \"LC03\":[\"20240419\"],\n",
    "  \"LC04\":[\"20240416\",\"20240417\"],\n",
    "  \"LC05\":[\"20240513\"],\n",
    "  \"LC06\":[\"20240513\"],\n",
    "}\n",
    "\n",
    "\n",
    "df_list = []\n",
    "for id,dates in id_date.items():\n",
    "    for date in dates:\n",
    "        path = f\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Scripts/Nithik/ACC_Arousal_Paper/LC_data/{id}_{date}_fixed.csv\"\n",
    "        df = pd.read_csv(path)\n",
    "        time = df[\"t\"]\n",
    "        pupil = np.array(zscore(df[\"pupil\"])) ###zscore pupil data\n",
    "        face = np.array(zscore(df[\"mot_whisk\"]))###zscore face data\n",
    "        dff = np.array(zscore(df[\"fp_lc\"])) ###zscore dff data\n",
    "\n",
    "        df = pd.DataFrame(pupil)\n",
    "        df = df.rename(columns= {0:\"pupil\"})\n",
    "        df[\"dff\"] = dff\n",
    "        df[\"face\"] = face\n",
    "        phases = np.angle(hilbert(df[\"pupil\"]))\n",
    "        df[\"phase_bin\"] = pd.cut(phases,128,labels = False)\n",
    "        df[\"ID\"] = id\n",
    "        df[\"Date\"] = date\n",
    "        df[\"Region\"] = \"LC\"\n",
    "\n",
    "        df_list.append(df)\n",
    "  \n",
    "lc_hilbert_df = pd.concat(df_list)\n",
    "\n",
    "              \n",
    "hilbert_df = pd.concat([acc_hilbert_df,lc_hilbert_df])\n",
    "###label hilbert_df\n",
    "def label_trial(row):\n",
    "    if 32<= row['phase_bin']<=64:\n",
    "      return 'Dilating'\n",
    "    elif 64< row['phase_bin']<=96:\n",
    "      return \"Constricting\"\n",
    "      \n",
    "hilbert_df['Pupil_State'] = hilbert_df.apply(label_trial, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hilbert_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(data = hilbert_df.groupby([\"ID\",\"phase_bin\",\"Region\",\"Pupil_State\"]).mean().reset_index().query(\"Region == 'ACC'\"), x = \"phase_bin\", y = \"pupil\", errorbar = \"se\",linewidth = 1,legend = None,color = \"dodgerblue\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###plot ACC hilbert over pupil\n",
    "\n",
    "plt.figure(figsize = (2,1.2))\n",
    "ax = sns.lineplot(data = hilbert_df.groupby([\"ID\",\"phase_bin\",\"Region\"]).mean().reset_index().query(\"Region == 'ACC'\"), x = \"phase_bin\", y = \"pupil\", errorbar = \"se\",linewidth = 1,legend = None,color = \"dodgerblue\")\n",
    "ax = sns.lineplot(data = hilbert_df.groupby([\"ID\",\"phase_bin\",\"Region\"]).mean().reset_index().query(\"Region == 'ACC'\"), x = \"phase_bin\", y = \"dff\", color = \"green\",errorbar = \"se\",linewidth = 1)\n",
    "\n",
    "format_ax(ax,(0,128),(-1,2),32,0.5)\n",
    "ax.set_xlabel(\"Pupil phase\")\n",
    "ax.set_ylabel('Z-Score')\n",
    "labels = [\"-π\",\"-π/2\",\"0\",\"π/2\",\"π\"]\n",
    "ax.set_xticklabels(labels)\n",
    "\n",
    "\n",
    "#plt.savefig(rf\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Manuscripts/2023-ACCArousal-CurrentBiology/SavedGraphs/ACC_hilbert.pdf\",format =\"pdf\",transparent = True,bbox_inches = \"tight\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###plot LC hilbert over pupil\n",
    "\n",
    "plt.figure(figsize = (2,1.2))\n",
    "ax = sns.lineplot(data = hilbert_df.groupby([\"ID\",\"phase_bin\",\"Region\"]).mean().reset_index().query(\"Region == 'LC'\"), x = \"phase_bin\", y = \"pupil\", color = \"dodgerblue\",errorbar = \"se\",linewidth = 1)\n",
    "ax = sns.lineplot(data = hilbert_df.groupby([\"ID\",\"phase_bin\",\"Region\"]).mean().reset_index().query(\"Region == 'LC'\"), x = \"phase_bin\", y = \"dff\", color = \"green\",errorbar = \"se\",linewidth = 1)\n",
    "\n",
    "format_ax(ax,(0,128),(-1,2),32,0.5)\n",
    "ax.set_xlabel(\"Pupil phase\")\n",
    "ax.set_ylabel('Z-Score')\n",
    "ax.set_xticklabels(labels)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(rf\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Manuscripts/2023-ACCArousal-CurrentBiology/SavedGraphs/LC_hilbert.pdf\",format =\"pdf\",transparent = True,bbox_inches = \"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###plot LC dff over ACC dff\n",
    "\n",
    "plt.figure(figsize = (2,1.2))\n",
    "ax = sns.lineplot(data = hilbert_df.groupby([\"ID\",\"phase_bin\",\"Region\"]).mean().reset_index(), x = \"phase_bin\", y = \"dff\", hue = \"Region\",errorbar = \"se\",linewidth = 1,legend = None,palette = [\"deeppink\",\"gold\"])\n",
    "\n",
    "format_ax(ax,(0,128),(-1,1.5),32,0.5)\n",
    "ax.set_xlabel(\"Pupil phase\")\n",
    "ax.set_ylabel('∆ F/F')\n",
    "ax.axvspan(32,64,alpha = 0.1,color = \"red\")\n",
    "ax.axvspan(64,96,alpha = 0.1,color = \"blue\")\n",
    "ax.set_xticklabels(labels)\n",
    "plt.savefig(rf\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Manuscripts/2023-ACCArousal-CurrentBiology/SavedGraphs/LCvsACC_hilbert.pdf\",format =\"pdf\",transparent = True,bbox_inches = \"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###plot LC vs ACC during dilating phase\n",
    "plt.figure(figsize = (0.6,1.2))\n",
    "g = sns.barplot(data = hilbert_df.groupby([\"ID\",'Pupil_State',\"Region\"]).mean().reset_index().query(\"Pupil_State == 'Dilating'\"), x = \"Region\", y = \"dff\",errorbar=\"se\",fill = None,errwidth= 1,edgecolor = \"red\")\n",
    "sns.stripplot(data = hilbert_df.groupby([\"ID\",'Pupil_State',\"Region\"]).mean().reset_index().query(\"Pupil_State == 'Dilating'\"), x = \"Region\", y = \"dff\",color = \"black\",alpha = 0.3,s = 4,jitter = 0.1)\n",
    "g.xaxis.label.set_visible(False)\n",
    "g.set_yticks(np.arange(0,1.4,0.4))\n",
    "g.set(ylim=(0, 1.2))\n",
    "g.set_ylabel('∆ F/F (z-scr)')\n",
    "plt.savefig(rf\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Manuscripts/2023-ACCArousal-CurrentBiology/SavedGraphs/dilating_dff.pdf\",format =\"pdf\",transparent = True,bbox_inches = \"tight\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###LC vs ACC during dilating phase stats\n",
    "stat_df = hilbert_df.groupby([\"ID\",'Pupil_State',\"Region\"]).mean().reset_index().query(\"Pupil_State == 'Constricting'\")\n",
    "group1 = stat_df[stat_df['Region']==\"LC\"]\n",
    "group2 = stat_df[stat_df['Region']==\"ACC\"]\n",
    "mannwhitneyu(group1[\"dff\"], group2[\"dff\"],nan_policy= \"omit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###plot LC vs ACC during constricting phase\n",
    "plt.figure(figsize = (0.6,1.2))\n",
    "g = sns.barplot(data = hilbert_df.groupby([\"ID\",'Pupil_State',\"Region\"]).mean().reset_index().query(\"Pupil_State == 'Constricting'\"), x = \"Region\", y = \"dff\",errorbar=\"se\",fill = None,errwidth= 1,edgecolor = \"blue\")\n",
    "sns.stripplot(data = hilbert_df.groupby([\"ID\",'Pupil_State',\"Region\"]).mean().reset_index().query(\"Pupil_State == 'Constricting'\"), x = \"Region\", y = \"dff\",color = \"black\",alpha = 0.3,s = 4,jitter = 0.1)\n",
    "g.xaxis.label.set_visible(False)\n",
    "g.set_yticks(np.arange(-0.6,1,0.3))\n",
    "g.set(ylim=(-0.6, 0.6))\n",
    "g.set_ylabel('∆ F/F (z-scr)')\n",
    "plt.savefig(rf\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Manuscripts/2023-ACCArousal-CurrentBiology/SavedGraphs/constricting_dff.pdf\",format =\"pdf\",transparent = True,bbox_inches = \"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###LC vs ACC during constricting phase stats\n",
    "stat_df = hilbert_df.groupby([\"ID\",'Pupil_State',\"Region\"]).mean().reset_index().query(\"Pupil_State == 'Constricting'\")\n",
    "group1 = stat_df[stat_df['Region']==\"LC\"]\n",
    "group2 = stat_df[stat_df['Region']==\"ACC\"]\n",
    "mannwhitneyu(group1[\"dff\"], group2[\"dff\"],nan_policy= \"omit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###compute dilating to constrict dff ratios\n",
    "constrict_dff = hilbert_df.groupby([\"ID\",'Pupil_State',\"Region\"]).mean().reset_index().query(\"Pupil_State == 'Constricting'\").reset_index()[\"dff\"]\n",
    "dilate_dff = hilbert_df.groupby([\"ID\",'Pupil_State',\"Region\"]).mean().reset_index().query(\"Pupil_State == 'Dilating'\").reset_index()[\"dff\"]\n",
    "ratios = constrict_dff/dilate_dff\n",
    "IDs = hilbert_df.groupby([\"ID\",'Pupil_State',\"Region\"]).mean().reset_index().query(\"Pupil_State == 'Constricting'\").reset_index()[\"ID\"]\n",
    "Regions = hilbert_df.groupby([\"ID\",'Pupil_State',\"Region\"]).mean().reset_index().query(\"Pupil_State == 'Constricting'\").reset_index()[\"Region\"]\n",
    "ratio_df = pd.DataFrame(IDs)\n",
    "ratio_df = ratio_df.rename(columns= {0:\"ID\"})\n",
    "ratio_df[\"Region\"] = Regions\n",
    "ratio_df[\"ratio\"] = ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###plot LC vs ACC ratios\n",
    "plt.figure(figsize = (0.6,1.2))\n",
    "g = sns.barplot(data = ratio_df, x = \"Region\", y = \"ratio\",errorbar=\"se\",fill = None,errwidth= 1)\n",
    "sns.stripplot(data = ratio_df, x = \"Region\", y = \"ratio\",color = \"black\",alpha = 0.3,s = 4,jitter = 0.1)\n",
    "g.xaxis.label.set_visible(False)\n",
    "g.set_yticks(np.arange(-0.9,0.9,0.3))\n",
    "g.set(ylim=(-0.9, 0.6))\n",
    "g.set_ylabel('Ratio')\n",
    "plt.savefig(rf\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Manuscripts/2023-ACCArousal-CurrentBiology/SavedGraphs/LCvsACC_hilbert_ratio.pdf\",format =\"pdf\",transparent = True,bbox_inches = \"tight\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###LC vs ACC during constricting phase stats\n",
    "stat_df = ratio_df\n",
    "group1 = ratio_df[ratio_df['Region']==\"LC\"]\n",
    "group2 = ratio_df[ratio_df['Region']==\"ACC\"]\n",
    "mannwhitneyu(group1[\"ratio\"], group2[\"ratio\"],nan_policy= \"omit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = hilbert_df.groupby([\"ID\",'Pupil_State',\"Region\"]).mean().reset_index()\n",
    "scatter_df = test.pivot(index='ID', columns='Pupil_State', values='dff').reset_index()\n",
    "scatter_df[\"Region\"] = Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (1.2,1.2))\n",
    "ax = sns.scatterplot(data = scatter_df, x = \"Constricting\", y = \"Dilating\",hue = \"Region\",size = 1,legend = None,palette = [\"deeppink\",\"gold\"])\n",
    "format_ax(ax,(-0.5,0),(0,0.5),0.25,0.25)\n",
    "#ax.plot([-0.5,0], [0,0.5], linewidth=1,linestyle = \"dashed\",color = \"black\")\n",
    "ax.set_ylabel('Dilating ∆ F/F')\n",
    "ax.set_xlabel('Constricting ∆ F/F')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###LC vs ACC Q4/Q1 ratio\n",
    "\n",
    "###get ACC quartile aligned bar df\n",
    "\n",
    "id_date = {\n",
    "  \"004113\":[\"20230808\"],\n",
    "  \"004114\":[\"20230808\",\"20230815\"],\n",
    "  \"004115\":[\"20230804\",\"20230808\",\"20230815\"],\n",
    "  \"004116\":[\"20230804\",\"20230808\",\"20230815\"],\n",
    "  \"004117\":[\"20230804\",\"20230808\",\"20230815\"],\n",
    "  \"004118\":[\"20230804\",\"20230808\",\"20230815\"]\n",
    " }\n",
    "labels = [\"1\",\"2\",\"3\",\"4\"]\n",
    "df_list = []\n",
    "for id,dates in id_date.items():\n",
    "    for date in dates:\n",
    "      \n",
    "        events = get_acc_events(id,date)\n",
    "        peak_ix = events[\"peak_ix\"]\n",
    "        onsets = [on for on in events[\"onsets\"]] ###get pupil onsets ix\n",
    "        onsets_ix = events[\"onsets\"]\n",
    "        offsets = [off for off in events[\"offsets\"]] ###get pupil offsets ix\n",
    "        amplitudes = events[\"amplitudes\"]\n",
    "        binned_amps = np.array(pd.qcut(amplitudes,q = 4,labels = labels))\n",
    "     \n",
    "\n",
    "  \n",
    "        face_path = f\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/ethanol_data/{id}/{date}/{date}_{id}_sess_1_FaceProcessed.csv\"\n",
    "        path = f\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/ethanol_data/{id}/{date}/{date}_{id}_sess_1_ProcessedData.csv\"\n",
    "        df = pd.read_csv(path)\n",
    "        pupil = np.array(df[\"Pupil Size\"])\n",
    "        time = np.array(df[\"Time\"])\n",
    "        speed = zscore((np.array(df[\"Running Speed\"])))\n",
    "        dff = np.array(df[\"dFF\"])\n",
    "        face = np.array(pd.read_csv(face_path)[\"Facial Movement\"])\n",
    "\n",
    "       \n",
    "\n",
    "     \n",
    "        for i,(on,off) in enumerate(zip(onsets,offsets)):\n",
    "          baseline = np.mean(dff[on - 40:on - 10])\n",
    "          pre_dff =np.mean(dff[on-5:on]) - baseline\n",
    "          during_dff = np.mean(dff[on:off]) - baseline\n",
    "\n",
    "          trial_dff = dff[on-10:off]\n",
    "          trial_dff = trial_dff - np.min(trial_dff)\n",
    "\n",
    "          ###calculate T50\n",
    "          max_ix = np.argmax(trial_dff)\n",
    "          peak_dff =  np.max(trial_dff)\n",
    "\n",
    "          target = peak_dff/2\n",
    "          t50_ix = np.where(trial_dff > target)[0][0]\n",
    "          t50 = t50_ix/20\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "          \n",
    "          \n",
    "\n",
    "\n",
    "          new_dict = { \"trial\" : i,\"ID\" : id, \"Date\": date,\"amp\":amplitudes[i],\"animal_amp_bin\":binned_amps[i],\"Pre Onset ∆ F/F\":pre_dff,\"∆ F/F\": during_dff,\"Half Max (s)\": half_max,\"T50 (s)\": t50}\n",
    "          df_list.append(new_dict)\n",
    "\n",
    "\n",
    "bar_df = pd.DataFrame.from_dict(df_list)\n",
    "q1 = bar_df.groupby([\"ID\",'animal_amp_bin']).mean().reset_index().query(\"animal_amp_bin == '1'\").reset_index()[\"∆ F/F\"]\n",
    "q4 = bar_df.groupby([\"ID\",'animal_amp_bin']).mean().reset_index().query(\"animal_amp_bin == '4'\").reset_index()[\"∆ F/F\"]\n",
    "ID = bar_df.groupby([\"ID\",'animal_amp_bin']).mean().reset_index().query(\"animal_amp_bin == '1'\").reset_index()[\"ID\"]\n",
    "dff_ratios = q4/q1\n",
    "acc_ratio = pd.DataFrame(ID)\n",
    "acc_ratio = acc_ratio.rename(columns= {0:\"ID\"})\n",
    "acc_ratio[\"ratio\"] = dff_ratios\n",
    "acc_ratio[\"Region\"] = \"ACC\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (1,1.25))\n",
    "g = sns.barplot(data = bar_df.groupby([\"ID\",'animal_amp_bin']).mean().reset_index(), x = \"animal_amp_bin\", y = \"Half Max (s)\",errorbar = \"se\",fill = None,errwidth= 1)\n",
    "sns.lineplot(data = bar_df.groupby([\"ID\",'animal_amp_bin']).mean().reset_index(), x = \"animal_amp_bin\", y = \"Half Max (s)\",units = \"ID\",estimator = None,color = \"black\",alpha = 0.3,linewidth = 0.5)\n",
    "\n",
    "g.set_xlabel(\"Dilation Amplitude\\n Quartile\")\n",
    "g.set_yticks(np.arange(0,12,2))\n",
    "g.set(ylim=(0,10))\n",
    "#plt.savefig(rf\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Manuscripts/2023-ACCArousal-CurrentBiology/SavedGraphs/FP_ampbin_dff_bar.pdf\",format =\"pdf\",transparent = True,bbox_inches = \"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (1,1.25))\n",
    "g = sns.barplot(data = bar_df.groupby([\"ID\",'animal_amp_bin']).mean().reset_index(), x = \"animal_amp_bin\", y = \"T50 (s)\",errorbar = \"se\",fill = None,errwidth= 1)\n",
    "sns.lineplot(data = bar_df.groupby([\"ID\",'animal_amp_bin']).mean().reset_index(), x = \"animal_amp_bin\", y = \"T50 (s)\",units = \"ID\",estimator = None,color = \"black\",alpha = 0.3,linewidth = 0.5)\n",
    "\n",
    "g.set_xlabel(\"Dilation Amplitude\\n Quartile\")\n",
    "# g.set_yticks(np.arange(0,30,2))\n",
    "# g.set(ylim=(0,30))\n",
    "#plt.savefig(rf\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Manuscripts/2023-ACCArousal-CurrentBiology/SavedGraphs/FP_ampbin_dff_bar.pdf\",format =\"pdf\",transparent = True,bbox_inches = \"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###LC vs ACC Q4/Q1 ratio\n",
    "\n",
    "###get LC quartile aligned bar df\n",
    "\n",
    "id_date = {\n",
    "  \"LC01\":[\"20240419\"],\n",
    "  \"LC02\":[\"20240416\"],\n",
    "  \"LC03\":[\"20240419\"],\n",
    "  \"LC04\":[\"20240416\",\"20240417\"],\n",
    "}\n",
    "labels = [\"1\",\"2\",\"3\",\"4\"]\n",
    "df_list = []\n",
    "for id,dates in id_date.items():\n",
    "    for date in dates:\n",
    "      \n",
    "        events = get_lc_events(id,date)\n",
    "        peak_ix = events[\"peak_ix\"]\n",
    "        onsets = [on for on in events[\"onsets\"]] ###get pupil onsets ix\n",
    "        onsets_ix = events[\"onsets\"]\n",
    "        offsets = [off for off in events[\"offsets\"]] ###get pupil offsets ix\n",
    "        amplitudes = events[\"amplitudes\"]\n",
    "        binned_amps = np.array(pd.qcut(amplitudes,q = 4,labels = labels))\n",
    "     \n",
    "\n",
    "  \n",
    "        path = f\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Scripts/Nithik/ACC_Arousal_Paper/LC_data/{id}_{date}.csv\"\n",
    "        df = pd.read_csv(path)\n",
    "        time = df[\"t\"]\n",
    "        pupil = np.array(zscore(df[\"pupil\"])) ###zscore pupil data\n",
    "        face = np.array(zscore(df[\"mot_whisk\"]))###zscore face data\n",
    "        dff = np.array(zscore(df[\"fp_lc\"])) ###zscore dff data\n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "     \n",
    "        for i,(on,off) in enumerate(zip(onsets,offsets)):\n",
    "          baseline = np.mean(dff[on - 40:on - 10])\n",
    "          pre_dff =np.mean(dff[on-5:on]) - baseline\n",
    "          during_dff = np.mean(dff[on:off]) - baseline\n",
    "       \n",
    "          trial_dff = dff[on-20:off]\n",
    "          trial_dff = trial_dff - np.min(trial_dff)\n",
    "          #trial_dff = np.convolve(trial_dff, np.ones(10)/10, mode='same')\n",
    "          # ###calculate half-max\n",
    "          # max_ix = np.argmax(trial_dff)\n",
    "\n",
    "          # peak_dff =  np.max(trial_dff) - np.min(trial_dff)\n",
    "          # target = peak_dff/2\n",
    "          #half_ix = np.where(trial_dff>target)[0][0]\n",
    "          # half_max = half_ix/20\n",
    "\n",
    "          ###calculate T50\n",
    "          max_ix = np.argmax(trial_dff)\n",
    "          peak_dff =  np.max(trial_dff) - np.min(trial_dff)\n",
    "\n",
    "          target = peak_dff/2\n",
    "          t50_ix = np.where(trial_dff > target)[0][0]\n",
    "          t50 = t50_ix/20\n",
    "\n",
    "\n",
    "          new_dict = { \"trial\" : i,\"ID\" : id, \"Date\": date,\"amp\":amplitudes[i],\"animal_amp_bin\":binned_amps[i],\"Pre Onset ∆ F/F\":pre_dff,\"∆ F/F\": during_dff,\"Half Max (s)\": half_max,\"T50 (s)\":t50}\n",
    "          df_list.append(new_dict)\n",
    "\n",
    "\n",
    "bar_df = pd.DataFrame.from_dict(df_list)\n",
    "q1 = bar_df.groupby([\"ID\",'animal_amp_bin']).mean().reset_index().query(\"animal_amp_bin == '1'\").reset_index()[\"∆ F/F\"]\n",
    "q4 = bar_df.groupby([\"ID\",'animal_amp_bin']).mean().reset_index().query(\"animal_amp_bin == '4'\").reset_index()[\"∆ F/F\"]\n",
    "ID = bar_df.groupby([\"ID\",'animal_amp_bin']).mean().reset_index().query(\"animal_amp_bin == '1'\").reset_index()[\"ID\"]\n",
    "dff_ratios = q4/q1\n",
    "lc_ratio = pd.DataFrame(ID)\n",
    "lc_ratio = lc_ratio.rename(columns= {0:\"ID\"})\n",
    "lc_ratio[\"ratio\"] = dff_ratios\n",
    "lc_ratio[\"Region\"] = \"LC\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (1,1.25))\n",
    "g = sns.barplot(data = bar_df.groupby([\"ID\",'animal_amp_bin']).mean().reset_index(), x = \"animal_amp_bin\", y = \"Half Max (s)\",errorbar = \"se\",fill = None,errwidth= 1)\n",
    "sns.lineplot(data = bar_df.groupby([\"ID\",'animal_amp_bin']).mean().reset_index(), x = \"animal_amp_bin\", y = \"Half Max (s)\",units = \"ID\",estimator = None,color = \"black\",alpha = 0.3,linewidth = 0.5)\n",
    "\n",
    "g.set_xlabel(\"Dilation Amplitude\\n Quartile\")\n",
    "g.set_yticks(np.arange(0,12,2))\n",
    "g.set(ylim=(0,10))\n",
    "#plt.savefig(rf\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Manuscripts/2023-ACCArousal-CurrentBiology/SavedGraphs/FP_ampbin_dff_bar.pdf\",format =\"pdf\",transparent = True,bbox_inches = \"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (1,1.25))\n",
    "g = sns.barplot(data = bar_df.groupby([\"ID\",'animal_amp_bin']).mean().reset_index(), x = \"animal_amp_bin\", y = \"T50 (s)\",errorbar = \"se\",fill = None,errwidth= 1)\n",
    "sns.lineplot(data = bar_df.groupby([\"ID\",'animal_amp_bin']).mean().reset_index(), x = \"animal_amp_bin\", y = \"T50 (s)\",units = \"ID\",estimator = None,color = \"black\",alpha = 0.3,linewidth = 0.5)\n",
    "\n",
    "g.set_xlabel(\"Dilation Amplitude\\n Quartile\")\n",
    "# g.set_yticks(np.arange(0,30,2))\n",
    "# g.set(ylim=(0,30))\n",
    "#plt.savefig(rf\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Manuscripts/2023-ACCArousal-CurrentBiology/SavedGraphs/FP_ampbin_dff_bar.pdf\",format =\"pdf\",transparent = True,bbox_inches = \"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_ratio_df = pd.concat([lc_ratio,acc_ratio])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###plot LC vs ACC ratios\n",
    "plt.figure(figsize = (0.8,1.2))\n",
    "g = sns.barplot(data = q_ratio_df, x = \"Region\", y = \"ratio\",errorbar=\"se\",fill = None,errwidth= 1)\n",
    "sns.stripplot(data = q_ratio_df, x = \"Region\", y = \"ratio\",color = \"black\",alpha = 0.3,s = 4,jitter = 0.1)\n",
    "g.xaxis.label.set_visible(False)\n",
    "g.set_yticks(np.arange(0,30,5))\n",
    "g.set(ylim=(0, 25))\n",
    "g.set_ylabel('Ratio')\n",
    "plt.savefig(rf\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Manuscripts/2023-ACCArousal-CurrentBiology/SavedGraphs/LCvsACC_q_ratio.pdf\",format =\"pdf\",transparent = True,bbox_inches = \"tight\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###LC vs ACC face-dff correlation stats\n",
    "stat_df = q_ratio_df\n",
    "group1 = stat_df[stat_df['Region']==\"LC\"]\n",
    "group2 = stat_df[stat_df['Region']==\"ACC\"]\n",
    "ttest_ind(group1[\"ratio\"], group2[\"ratio\"],nan_policy= \"omit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###try t50 and t5 with averaged traces\n",
    "\n",
    "id_date = {\n",
    "  \"004113\":[\"20230808\"],\n",
    "  \"004114\":[\"20230808\",\"20230815\"],\n",
    "  \"004115\":[\"20230804\",\"20230808\",\"20230815\"],\n",
    "  \"004116\":[\"20230804\",\"20230808\",\"20230815\"],\n",
    "  \"004117\":[\"20230804\",\"20230808\",\"20230815\"],\n",
    "  \"004118\":[\"20230804\",\"20230808\",\"20230815\"]\n",
    "}\n",
    "\n",
    "df_list = []\n",
    "for id,dates in id_date.items():\n",
    "    for date in dates:\n",
    "      \n",
    "        events = get_acc_events(id,date)\n",
    "        onsets = [on/20 for on in events[\"onsets\"]] ###get pupil onsets\n",
    "        onsets_ix = events[\"onsets\"]\n",
    "  \n",
    "        face_path = f\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/ethanol_data/{id}/{date}/{date}_{id}_sess_1_FaceProcessed.csv\"\n",
    "        path = f\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/ethanol_data/{id}/{date}/{date}_{id}_sess_1_ProcessedData.csv\"\n",
    "        df = pd.read_csv(path)\n",
    "        pupil = np.array(df[\"Pupil Size\"])\n",
    "        time = np.array(df[\"Time\"])\n",
    "        speed = zscore(np.array(df[\"Running Speed\"]))\n",
    "        dff = np.array(df[\"dFF\"])\n",
    "        face = np.array(pd.read_csv(face_path)[\"Facial Movement\"])\n",
    "\n",
    "        dil_matrix,dil_times = trial_align(onsets,time,pupil,fps = 20,pre = 2, post = 10 )\n",
    "        trial_matrix,trial_times = trial_align(onsets,time,dff,fps = 20,pre = 2, post = 10)\n",
    "        face_matrix,face_times = trial_align(onsets,time,face,fps = 20,pre = 2, post = 10)\n",
    "\n",
    "        dff_trial = np.mean(trial_matrix,0)\n",
    "        dff_trial = dff_trial - np.min(dff_trial)\n",
    "        max_ix = np.argmax(dff_trial)\n",
    "        min_ix = np.argmin(dff_trial)\n",
    "        peak_dff =  np.max(dff_trial)\n",
    "        target = peak_dff/2\n",
    "        t50_ix = np.where(dff_trial[min_ix:] > target)[0][0] + min_ix\n",
    "       # t50 = (t50_ix - min_ix)/20 ###relative to minimum\n",
    "        t50 = (t50_ix - 40)/20 ###relative to dilation onset\n",
    "\n",
    "  \n",
    "\n",
    "        ###find onset of dff by finding continuous region from min to max\n",
    "\n",
    "        regions = list(groupSequence(dff_trial[min_ix:max_ix]))\n",
    "        corrected_regions = [region for region in regions if len(region) >=5 ]\n",
    "        first_region = corrected_regions[0]\n",
    "        region_ix = [np.where(dff_trial[min_ix:max_ix] == val)[0][0] + min_ix for val in first_region]\n",
    "        \n",
    "        onset_ix,offset_ix = region_ix[0],region_ix[-1]\n",
    "        onset_time = (onset_ix-40)/20\n",
    "\n",
    "\n",
    "                \n",
    "        new_dict = {\"ID\" : id, \"Date\": date,\"T50 (s)\": t50,\"Region\":\"ACC\",\"Onset\":onset_time}\n",
    "        df_list.append(new_dict)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # ax = plt.gca()\n",
    "        # plt.plot(dff_trial)\n",
    "        # ax.axvline(40)\n",
    "        # ax.axvspan(onset_ix,offset_ix,alpha = 0.2)\n",
    "        # #ax.axhline(target)\n",
    "\n",
    "        # plt.scatter(max_ix,peak_dff,color = \"blue\")\n",
    "        # plt.scatter(t5_ix,dff_trial[t5_ix],color = \"red\")\n",
    "\n",
    "        # plt.show()\n",
    "        # plt.clf()\n",
    "    \n",
    "\n",
    "      \n",
    "acc_t50_df = pd.DataFrame.from_dict(df_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_bar_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###try t50 and t5 with averaged traces for LC\n",
    "\n",
    "\n",
    "id_date = {\n",
    "  \"LC01\":[\"20240419\"],\n",
    "  \"LC02\":[\"20240416\"],\n",
    "  \"LC03\":[\"20240419\"],\n",
    "  \"LC04\":[\"20240416\",\"20240417\"],\n",
    "  \"LC05\":[\"20240513\"],\n",
    "  \"LC06\":[\"20240513\"],\n",
    "}\n",
    "\n",
    "df_list = []\n",
    "for id,dates in id_date.items():\n",
    "    for date in dates:\n",
    "      \n",
    "        events = get_lc_events(id,date)\n",
    "        onsets = [on/20 for on in events[\"onsets\"]] ###get pupil onsets\n",
    "        onsets_ix = events[\"onsets\"]\n",
    "  \n",
    "       \n",
    "        path = f\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Scripts/Nithik/ACC_Arousal_Paper/LC_data/{id}_{date}_fixed.csv\"\n",
    "        df = pd.read_csv(path)\n",
    "        time = df[\"t\"]\n",
    "        pupil = np.array(zscore(df[\"pupil\"])) ###zscore pupil data\n",
    "        face = np.array(zscore(df[\"mot_whisk\"]))###zscore face data\n",
    "        dff = np.array(zscore(df[\"fp_lc\"])) ###zscore dff data\n",
    "\n",
    "        dil_matrix,dil_times = trial_align(onsets,time,pupil,fps = 20,pre = 2, post = 10 )\n",
    "        trial_matrix,trial_times = trial_align(onsets,time,dff,fps = 20,pre = 2, post = 10)\n",
    "        face_matrix,face_times = trial_align(onsets,time,face,fps = 20,pre = 2, post = 10)\n",
    "\n",
    "        dff_trial = np.nanmean(trial_matrix,0)\n",
    "        dff_trial = dff_trial - np.min(dff_trial)\n",
    "        max_ix = np.argmax(dff_trial)\n",
    "        min_ix = np.argmin(dff_trial)\n",
    "        peak_dff =  np.max(dff_trial)\n",
    "        target = peak_dff/2\n",
    "        t50_ix = np.where(dff_trial[min_ix:] > target)[0][0] + min_ix\n",
    "        t50 = (t50_ix - 40)/20 ###relative to dilation onset\n",
    "\n",
    "   \n",
    "      \n",
    "        ###find onset of dff by finding continuous region from min to max\n",
    "\n",
    "        regions = list(groupSequence(dff_trial[min_ix:max_ix]))\n",
    "        corrected_regions = [region for region in regions if len(region) >=5 ]\n",
    "        first_region = corrected_regions[0]\n",
    "        region_ix = [np.where(dff_trial[min_ix:max_ix] == val)[0][0] + min_ix for val in first_region]\n",
    "        \n",
    "        onset_ix,offset_ix = region_ix[0],region_ix[-1]\n",
    "        onset_time = (onset_ix-40)/20\n",
    "\n",
    "                \n",
    "        new_dict = {\"ID\" : id, \"Date\": date,\"T50 (s)\": t50,\"Region\":\"LC\",\"Onset\":onset_time}\n",
    "        df_list.append(new_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # ax = plt.gca()\n",
    "        # plt.plot(dff_trial)\n",
    "        # ax.axvline(40)\n",
    "        # ax.axvspan(onset_ix,offset_ix,alpha = 0.2)\n",
    "\n",
    "        # #ax.axhline(target)\n",
    "\n",
    "        # plt.scatter(max_ix,peak_dff,color = \"blue\")\n",
    "        # plt.scatter(min_ix,dff_trial[min_ix],color = \"black\")\n",
    "\n",
    "        # plt.scatter(t50_ix,dff_trial[t50_ix],color = \"red\")\n",
    "\n",
    "        # plt.show()\n",
    "        # plt.clf()\n",
    "    \n",
    "\n",
    "      \n",
    "lc_t50_df = pd.DataFrame.from_dict(df_list)\n",
    "t50_df = pd.concat([lc_t50_df,acc_t50_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t50_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###LC vs ACC t50\n",
    "plt.figure(figsize = (0.6,1.2))\n",
    "g = sns.barplot(data = t50_df.groupby([\"ID\",\"Region\"]).mean().reset_index(), x = \"Region\", y = \"T50 (s)\",errorbar=\"se\",fill = None,errwidth= 1,order = [\"ACC\",\"LC\"])\n",
    "sns.stripplot(data = t50_df.groupby([\"ID\",\"Region\"]).mean().reset_index(), x = \"Region\", y = \"T50 (s)\",color = \"black\",alpha = 0.3,s = 4,jitter = 0.1,order = [\"ACC\",\"LC\"])\n",
    "g.xaxis.label.set_visible(False)\n",
    "g.set_yticks(np.arange(-1,0.5,.5))\n",
    "g.set(ylim=(-1, 0))\n",
    "g.set_ylabel(\"T50 (s)\")\n",
    "plt.savefig(rf\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Manuscripts/2023-ACCArousal-CurrentBiology/SavedGraphs/t50.pdf\",format =\"pdf\",transparent = True,bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###LC vs ACC activity onset\n",
    "plt.figure(figsize = (0.6,1.2))\n",
    "g = sns.barplot(data = t50_df.groupby([\"ID\",\"Region\"]).mean().reset_index(), x = \"Region\", y = \"Onset\",errorbar=\"se\",fill = None,errwidth= 1,order =[\"ACC\",\"LC\"] )\n",
    "sns.stripplot(data = t50_df.groupby([\"ID\",\"Region\"]).mean().reset_index(), x = \"Region\", y = \"Onset\",color = \"black\",alpha = 0.3,s = 4,jitter = 0.1,order = [\"ACC\",\"LC\"])\n",
    "g.xaxis.label.set_visible(False)\n",
    "g.set_yticks(np.arange(-1.5,0.5,.5))\n",
    "g.set(ylim=(-1.5, 0))\n",
    "g.set_ylabel(\"Activity Onset (s)\")\n",
    "plt.savefig(rf\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Manuscripts/2023-ACCArousal-CurrentBiology/SavedGraphs/activity_onset.pdf\",format =\"pdf\",transparent = True,bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###LC vs ACC face-dff correlation stats\n",
    "stat_df = t50_df.groupby([\"ID\",\"Region\"]).mean().reset_index()\n",
    "group1 = stat_df[stat_df['Region']==\"LC\"]\n",
    "group2 = stat_df[stat_df['Region']==\"ACC\"]\n",
    "mannwhitneyu(group1[\"T50 (s)\"], group2[\"T50 (s)\"],nan_policy= \"omit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t50_df.groupby([\"ID\",\"Region\"]).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###LC vs ACC activity onset stats\n",
    "stat_df = t50_df.groupby([\"ID\",\"Region\"]).mean().reset_index()\n",
    "group1 = stat_df[stat_df['Region']==\"LC\"]\n",
    "group2 = stat_df[stat_df['Region']==\"ACC\"]\n",
    "mannwhitneyu(group1[\"Onset\"], group2[\"Onset\"],nan_policy= \"omit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###LC vs ACC onset dff - peak dff\n",
    "\n",
    "\n",
    "id_date = {\n",
    "  \"LC01\":[\"20240419\"],\n",
    "  \"LC02\":[\"20240416\"],\n",
    "  \"LC03\":[\"20240419\"],\n",
    "  \"LC04\":[\"20240416\",\"20240417\"],\n",
    "  \"LC05\":[\"20240513\"],\n",
    "  \"LC06\":[\"20240513\"],\n",
    "}\n",
    "\n",
    "df_list = []\n",
    "for id,dates in id_date.items():\n",
    "    for date in dates:\n",
    "      \n",
    "        events = get_lc_events(id,date)\n",
    "        peak_ix = events[\"peak_ix\"]\n",
    "        onsets = [on for on in events[\"onsets\"]] ###get pupil onsets ix\n",
    "        onsets_ix = events[\"onsets\"]\n",
    "        offsets = [off for off in events[\"offsets\"]] ###get pupil offsets ix\n",
    "        amplitudes = events[\"amplitudes\"]\n",
    "     \n",
    "     \n",
    "\n",
    "  \n",
    "        path = f\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Scripts/Nithik/ACC_Arousal_Paper/LC_data/{id}_{date}_fixed.csv\"\n",
    "        df = pd.read_csv(path)\n",
    "        time = df[\"t\"]\n",
    "        pupil = np.array(zscore(df[\"pupil\"])) ###zscore pupil data\n",
    "        face = np.array(zscore(df[\"mot_whisk\"]))###zscore face data\n",
    "        dff = np.array(zscore(df[\"fp_lc\"])) ###zscore dff data\n",
    "\n",
    "       \n",
    "\n",
    "     \n",
    "        for i,(on,peak) in enumerate(zip(onsets_ix,peak_ix)):\n",
    "            delta = dff[peak] - dff[on]\n",
    " \n",
    "\n",
    "\n",
    "            new_dict = { \"trial\" : i,\"ID\" : id, \"Date\": date,\"Peak-Onset\":delta,\"Region\":\"LC\"}\n",
    "            df_list.append(new_dict)\n",
    "\n",
    "\n",
    "lc_bar_df = pd.DataFrame.from_dict(df_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_bar_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###LC vs ACC onset dff - peak dff\n",
    "\n",
    "\n",
    "\n",
    "id_date = {\n",
    "  \"004113\":[\"20230808\"],\n",
    "  \"004114\":[\"20230808\",\"20230815\"],\n",
    "  \"004115\":[\"20230804\",\"20230808\",\"20230815\"],\n",
    "  \"004116\":[\"20230804\",\"20230808\",\"20230815\"],\n",
    "  \"004117\":[\"20230804\",\"20230808\",\"20230815\"],\n",
    "  \"004118\":[\"20230804\",\"20230808\",\"20230815\"]\n",
    "}\n",
    "\n",
    "df_list = []\n",
    "for id,dates in id_date.items():\n",
    "    for date in dates:\n",
    "      \n",
    "        events = get_acc_events(id,date)\n",
    "        peak_ix = events[\"peak_ix\"]\n",
    "        onsets = [on for on in events[\"onsets\"]] ###get pupil onsets ix\n",
    "        onsets_ix = events[\"onsets\"]\n",
    "        offsets = [off for off in events[\"offsets\"]] ###get pupil offsets ix\n",
    "        amplitudes = events[\"amplitudes\"]\n",
    "     \n",
    "     \n",
    "\n",
    "  \n",
    "        face_path = f\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/ethanol_data/{id}/{date}/{date}_{id}_sess_1_FaceProcessed.csv\"\n",
    "        path = f\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/ethanol_data/{id}/{date}/{date}_{id}_sess_1_ProcessedData.csv\"\n",
    "        df = pd.read_csv(path)\n",
    "        pupil = np.array(df[\"Pupil Size\"])\n",
    "        time = np.array(df[\"Time\"])\n",
    "        speed = zscore(np.array(df[\"Running Speed\"]))\n",
    "        dff = np.array(df[\"dFF\"])\n",
    "        face = np.array(pd.read_csv(face_path)[\"Facial Movement\"])\n",
    "\n",
    "       \n",
    "\n",
    "     \n",
    "        for i,(on,peak) in enumerate(zip(onsets_ix,peak_ix)):\n",
    "            delta = dff[peak] - dff[on]\n",
    " \n",
    "\n",
    "\n",
    "            new_dict = { \"trial\" : i,\"ID\" : id, \"Date\": date,\"Peak-Onset\":delta,\"Region\":\"ACC\"}\n",
    "            df_list.append(new_dict)\n",
    "\n",
    "\n",
    "acc_bar_df = pd.DataFrame.from_dict(df_list)\n",
    "bar_df = pd.concat([lc_bar_df,acc_bar_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###LC vs ACC face-dff correlation\n",
    "plt.figure(figsize = (0.6,1.2))\n",
    "g = sns.barplot(data = bar_df.groupby([\"ID\",\"Region\"]).mean().reset_index(), x = \"Region\", y = \"Peak-Onset\",errorbar=\"se\",fill = None,errwidth= 1)\n",
    "sns.stripplot(data = bar_df.groupby([\"ID\",\"Region\"]).mean().reset_index(), x = \"Region\", y = \"Peak-Onset\",color = \"black\",alpha = 0.3,s = 4,jitter = 0.1)\n",
    "g.xaxis.label.set_visible(False)\n",
    "g.set_yticks(np.arange(-2,1,0.5))\n",
    "g.set(ylim=(-2, 0.5))\n",
    "g.set_ylabel(\"Peak - Onset (∆ F/F)\")\n",
    "plt.savefig(rf\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Manuscripts/2023-ACCArousal-CurrentBiology/SavedGraphs/peak-onset.pdf\",format =\"pdf\",transparent = True,bbox_inches = \"tight\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###LC vs ACC face-dff correlation stats\n",
    "stat_df = bar_df\n",
    "group1 = stat_df[stat_df['Region']==\"LC\"]\n",
    "group2 = stat_df[stat_df['Region']==\"ACC\"]\n",
    "mannwhitneyu(group1[\"Peak-Onset\"], group2[\"Peak-Onset\"],nan_policy= \"omit\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HudaLab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
