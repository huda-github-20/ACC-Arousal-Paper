{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pupil_classv2 as pc\n",
    "import math\n",
    "from statistics import mean\n",
    "import csv\n",
    "from timestamps import new_timestamps\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from helper import *\n",
    "import tdt\n",
    "from scipy.signal import find_peaks, peak_widths,resample,correlate, correlation_lags,peak_prominences,resample,butter, lfilter, freqz,medfilt,hilbert\n",
    "from scipy.stats import pearsonr,wilcoxon,mannwhitneyu,kruskal\n",
    "import os\n",
    "from fp_helper import *\n",
    "from matplotlib import rcParams\n",
    "import cv2\n",
    "from scipy.stats import ttest_ind,ttest_rel,zscore,f_oneway\n",
    "from sklearn.linear_model import Ridge,RidgeCV\n",
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "from random import randint\n",
    "from scipy.ndimage import median_filter\n",
    "import scikit_posthocs as sp\n",
    "import statsmodels.api as sm \n",
    "from statsmodels.formula.api import ols \n",
    "from statsmodels.stats.anova import AnovaRM \n",
    "\n",
    "\n",
    "\n",
    "params = {\n",
    "        \"font.family\" : \"Arial\",\n",
    "        'pdf.fonttype' : 42,\n",
    "        'axes.labelsize': 10,\n",
    "        'axes.titlesize': 11,\n",
    "        'axes.linewidth': 0.5,\n",
    "        'xtick.labelsize':9,\n",
    "        'xtick.major.width':0.5,\n",
    "        'ytick.major.width':0.5,\n",
    "        'ytick.labelsize':9,\n",
    "        'axes.spines.top':False,\n",
    "        'axes.spines.right':False\n",
    "         }\n",
    "rcParams['figure.figsize'] = 21.7,8.27\n",
    "rcParams.update(params)\n",
    "def format_ax(ax,xlim,ylim,xspace,yspace):\n",
    "   \n",
    "    ax.set_xticks(np.arange(xlim[0],xlim[1]+ xspace,xspace))\n",
    "    ax.set_yticks(np.arange(ylim[0],ylim[1]+ yspace,yspace))\n",
    "\n",
    "    ax.set(ylim=(ylim[0], ylim[1]))\n",
    "    ax.set(xlim=(xlim[0], xlim[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contiguous_regions(condition):\n",
    "    \"\"\"Finds contiguous True regions of the boolean array \"condition\". Returns\n",
    "    a 2D array where the first column is the start index of the region and the\n",
    "    second column is the end index.\"\"\"\n",
    "\n",
    "    # Find the indicies of changes in \"condition\"\n",
    "    d = np.diff(condition)\n",
    "    idx, = d.nonzero() \n",
    "\n",
    "    # We need to start things after the change in \"condition\". Therefore, \n",
    "    # we'll shift the index by 1 to the right.\n",
    "    idx += 1\n",
    "\n",
    "    if condition[0]:\n",
    "        # If the start of condition is True prepend a 0\n",
    "        idx = np.r_[0, idx]\n",
    "\n",
    "    if condition[-1]:\n",
    "        # If the end of condition is True, append the length of the array\n",
    "        idx = np.r_[idx, condition.size] # Edit\n",
    "\n",
    "    # Reshape the result into two columns\n",
    "    idx.shape = (-1,2)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###low pass filter pupil\n",
    "def filter_pupil(pupil,order = 1,cutoff = 1,fs = 20):\n",
    "    def butter_lowpass(cutoff, fs, order=5):\n",
    "        return butter(order, cutoff, fs=fs, btype='low', analog=False)\n",
    "\n",
    "    def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "        b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "        y = lfilter(b, a, data)\n",
    "        return y\n",
    "\n",
    "    return butter_lowpass_filter(pupil, cutoff, fs, order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get pupil events\n",
    "###get events from all sessions\n",
    "\n",
    "def get_pupil_events(id,date):\n",
    "    id = id\n",
    "    date = date\n",
    "    path = f\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Scripts/Nithik/ACC_Arousal_Paper/LC_data/{id}_{date}_fixed.csv\"\n",
    "    df = pd.read_csv(path)\n",
    "    time = df[\"t\"]\n",
    "    pupil = np.array(zscore(df[\"pupil\"])) ###zscore pupil data\n",
    "\n",
    "\n",
    "    ###Onset detection alogrithm\n",
    "\n",
    "    \n",
    "    filter = filter_pupil(pupil) ###first apply low pass filter to pupil trace\n",
    "\n",
    "    def groupSequence(x): \n",
    "        it = iter(x) \n",
    "        prev, res = next(it), [] \n",
    "    \n",
    "        while prev is not None: \n",
    "            start = next(it, None) \n",
    "    \n",
    "            if start and start > prev:\n",
    "\n",
    "                res.append(prev) \n",
    "            elif res: \n",
    "                yield list(res + [prev]) \n",
    "                res = [] \n",
    "            prev = start \n",
    "\n",
    "\n",
    "    regions = list(groupSequence(filter))\n",
    "    corrected_regions = [region for region in regions if len(region) >=15 ] ###only include regions that are >750ms\n",
    "    corrected_regions = [region for region in corrected_regions if region[0]<np.median(filter) ] ###only include onsets that occur below z = median\n",
    "\n",
    "    region_ix = [[np.where(filter == val)[0][0] for val in region] for region in corrected_regions] ### get indices for each region\n",
    "\n",
    "\n",
    "    ##join regions that are near eachother\n",
    "    new = []\n",
    "    for i,first in enumerate(region_ix):\n",
    "        if i < len(region_ix)-1:\n",
    "            second = region_ix[i + 1]\n",
    "            end = first[-1]\n",
    "            start = second[0]\n",
    "            if first[0] - region_ix[i - 1][-1]>20:\n",
    "                if start-end<= 20:\n",
    "                    #print(first[0]/20,second[0]/20)\n",
    "                    new.append(first + second)\n",
    "                else:\n",
    "                    new.append(first)\n",
    "    region_ix = new\n",
    "    corrected_regions = [filter[region[0]:region[-1]] for region in region_ix]\n",
    "\n",
    "\n",
    "    new = []\n",
    "    for i,first in enumerate(region_ix):\n",
    "        if i < len(region_ix)-1:\n",
    "            second = region_ix[i + 1]\n",
    "            end = first[-1]\n",
    "            start = second[0]\n",
    "            if first[0] - region_ix[i - 1][-1]>10:\n",
    "                if start-end<= 10:\n",
    "                    #print(first[0]/20,second[0]/20)\n",
    "                    new.append(first + second)\n",
    "                else:\n",
    "                    new.append(first)\n",
    "    region_ix = new\n",
    "    corrected_regions = [filter[region[0]:region[-1]] for region in region_ix]\n",
    "    onsets_ix = [region[0] for region in region_ix]\n",
    "\n",
    "\n",
    "    ###get offsets and durations for pupil event\n",
    "    offset_ix = []\n",
    "    durations = []\n",
    "    for i,(region,index) in enumerate(zip(corrected_regions,region_ix)):\n",
    "        if i < len(region_ix)-1:\n",
    "            start = index[-1] ###end of region\n",
    "            end = region_ix[i+1][0] ### start of next region\n",
    "            onset_y = region[0]\n",
    "            offsets = np.where(filter[start:end] <= onset_y) ###find ix of first point that goes below onset \n",
    "        if len(offsets[0]) == 0: ###if it never goes below onset then use lowest value\n",
    "            offset = start + np.argmin(filter[start:end])\n",
    "        else:\n",
    "            offset = start + offsets[0][0]\n",
    "\n",
    "\n",
    "        offset_ix.append(offset)\n",
    "\n",
    "        durations.append((offset-index[0])/20)\n",
    "\n",
    "    ###handle last pupil event\n",
    "    start = region_ix[-1][-1]\n",
    "    end = len(pupil)\n",
    "    onset_y = corrected_regions[-1][0]\n",
    "    offsets = np.where(filter[start:end] <= onset_y)\n",
    "    if len(offsets[0]) == 0:\n",
    "        offset = end-1\n",
    "    else:\n",
    "        offset = start + np.argmin(filter[start:end])\n",
    "\n",
    "    offset_ix[-1] = offset\n",
    "\n",
    "    durations[-1] = (offset-region_ix[-1][0])/20\n",
    "\n",
    "    ###get pupil event amplitudes\n",
    "    amplitudes = []\n",
    "    amplitudes_ix = []\n",
    "    for on,off in zip(onsets_ix,offset_ix):\n",
    "        #print(on,off)\n",
    "        amplitudes.append(max(filter[on:off])-filter[on])\n",
    "        amplitudes_ix.append(on + np.argmax(filter[on:off]))\n",
    "\n",
    "    ###get pupil event slopes\n",
    "    slopes = []\n",
    "    for region in corrected_regions:\n",
    "        run = len(region)/20\n",
    "        rise = region[-1]-region[0]\n",
    "        slopes.append(rise/run)\n",
    "\n",
    "    # ###get dff data\n",
    "    # aucs = []\n",
    "    # peak_dffs = []\n",
    "    # mean_dffs = []\n",
    "    # for onset,offset in zip(onsets_ix,offset_ix):\n",
    "    #     baseline = np.mean(dff[onset-40:onset-10])\n",
    "    #     peak_dffs.append(max(dff[onset:offset]) - np.mean(dff[onset-30:onset]))\n",
    "    #     mean_dffs.append(np.mean(dff[onset:offset])- np.mean(dff[onset-20:onset]))\n",
    "\n",
    "    ###create dictionary\n",
    "\n",
    "    events_dict = {\"durations\" :durations,\n",
    "    \"amplitudes\": amplitudes,\n",
    "    \"slopes\" : slopes,\n",
    "    \"onsets\" : onsets_ix,\n",
    "    \"offsets\" : offset_ix,\n",
    "    \"peak_ix\" : amplitudes_ix,\n",
    "    \"ID\" : [id] * len(durations),\n",
    "    \"Date\" : [date] * len(durations),\n",
    "    #\"peak_dff\" : peak_dffs,\n",
    "    #\"mean_dff\" : mean_dffs,\n",
    "    }\n",
    "    return pd.DataFrame.from_dict(events_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###correlation with dff\n",
    "\n",
    "id_date = {\n",
    "  \"LC01\":[\"20240419\"],\n",
    "  \"LC02\":[\"20240416\"],\n",
    "  \"LC03\":[\"20240419\"],\n",
    "  \"LC04\":[\"20240416\",\"20240417\"],\n",
    "  \"LC05\":[\"20240513\"],\n",
    "  \"LC06\":[\"20240513\"],\n",
    "\n",
    "\n",
    "\n",
    "}\n",
    "df_list = []\n",
    "\n",
    "\n",
    "for id,dates in id_date.items():\n",
    "    for date in dates:\n",
    "      path = f\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Scripts/Nithik/ACC_Arousal_Paper/LC_data/{id}_{date}_fixed.csv\"\n",
    "      df = pd.read_csv(path)\n",
    "      time = df[\"t\"]\n",
    "      pupil = np.array(zscore(df[\"pupil\"])) ###zscore pupil data\n",
    "      face = np.array(zscore(df[\"mot_whisk\"]))###zscore face data\n",
    "      dff = np.array(zscore(df[\"fp_lc\"])) ###zscore dff data\n",
    "\n",
    "\n",
    "      new_dict = {\"R\":pearsonr(dff,pupil)[0], \"type\": \"P-D\", \"ID\" : id, \"Date\": date}\n",
    "      df_list.append(new_dict)\n",
    "      # new_dict = {\"R\":pearsonr(face,pupil)[0], \"type\": \"F-P\", \"ID\" : id, \"Date\": date}\n",
    "      # df_list.append(new_dict)\n",
    "      new_dict = {\"R\":pearsonr(dff,face)[0], \"type\": \"F-D\", \"ID\" : id, \"Date\": date}\n",
    "      df_list.append(new_dict)\n",
    "\n",
    "r_df = pd.DataFrame.from_dict(df_list)\n",
    "\n",
    "plt.figure(figsize = (0.8,1.2))\n",
    "g = sns.barplot(data = r_df.groupby([\"ID\",'type']).mean().reset_index(), x = \"type\", y = \"R\",errorbar=\"se\",fill = None,errwidth= 1)\n",
    "sns.stripplot(data = r_df.groupby([\"ID\",'type']).mean().reset_index(), x = \"type\", y = \"R\",color = \"black\",alpha = 0.3,s = 4,jitter = 0.1)\n",
    "\n",
    "g.set_yticks(np.arange(-0.2,1,0.2))\n",
    "g.set(ylim=(-0.2, 0.8))\n",
    "g.xaxis.label.set_visible(False)\n",
    "\n",
    "#plt.savefig(rf\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Manuscripts/2023-ACCArousal-CurrentBiology/SavedGraphs/FP_dffcorr_bar.pdf\",format =\"pdf\",transparent = True,bbox_inches = \"tight\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### do lag analysis based on pupil-onset aligned traces\n",
    "pre = 2\n",
    "post =2\n",
    "\n",
    "\n",
    "id_date = {\n",
    "  \"LC01\":[\"20240419\"],\n",
    "  \"LC02\":[\"20240416\"],\n",
    "  \"LC03\":[\"20240419\"],\n",
    "  \"LC04\":[\"20240416\",\"20240417\"],\n",
    "  \"LC05\":[\"20240513\"],\n",
    "  \"LC06\":[\"20240513\"],\n",
    "}\n",
    "\n",
    "\n",
    "df_list = []\n",
    "graph_df_list = []\n",
    "for id,dates in id_date.items():\n",
    "    for date in dates:\n",
    "      \n",
    "        events = get_pupil_events(id,date)\n",
    "        onsets = [on/20 for on in events[\"onsets\"]] ###get pupil onsets\n",
    "        amplitudes = events[\"amplitudes\"]\n",
    "\n",
    "        path = f\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Scripts/Nithik/ACC_Arousal_Paper/LC_data/{id}_{date}_fixed.csv\"\n",
    "        df = pd.read_csv(path)\n",
    "        time = df[\"t\"]\n",
    "        pupil = np.array(zscore(df[\"pupil\"])) ###zscore pupil data\n",
    "        face = np.array(zscore(df[\"mot_whisk\"]))###zscore face data\n",
    "        dff = np.array(zscore(df[\"fp_lc\"])) ###zscore dff data\n",
    "\n",
    "        dil_matrix,dil_times = trial_align(onsets,time,pupil,fps = 20,pre = pre, post = post)\n",
    "        face_matrix,face_times = trial_align(onsets,time,face,fps = 20,pre = pre, post = post)\n",
    "        dff_matrix,dff_times = trial_align(onsets,time,dff,fps = 20,pre = pre, post = post)\n",
    "\n",
    "\n",
    "        corr = correlate(np.mean(dil_matrix,axis=0), np.mean(dff_matrix,axis = 0))\n",
    "        lags = correlation_lags(len(np.mean(dil_matrix,axis=0)), len(np.mean(dff_matrix,axis = 0)))\n",
    "        lags = lags/20\n",
    "        corr /= np.max(corr)\n",
    "        i = np.argmax(corr)\n",
    "        delay = lags[i]\n",
    "        lag_dict = {\"Cross-Correlation Delay (s)\" : delay,\"ID\": id, \"date\" : date,\"type\":\"P-D\"}\n",
    "        df_list.append(lag_dict)\n",
    "\n",
    "        for lag,c in zip(lags,corr):\n",
    "            graph_dict = {\"Lags (s)\": lag,\"Cross-Correlation\": c,\"ID\": id, \"date\" : date,\"type\":\"P-D\"}\n",
    "            graph_df_list.append(graph_dict)\n",
    "        \n",
    "\n",
    "        corr = correlate(np.mean(face_matrix,axis=0), np.mean(dff_matrix,axis = 0))\n",
    "        lags = correlation_lags(len(np.mean(face_matrix,axis=0)), len(np.mean(dff_matrix,axis = 0)))\n",
    "        lags = lags/20\n",
    "        corr /= np.max(corr)\n",
    "        i = np.argmax(corr)\n",
    "        delay = lags[i]\n",
    "        lag_dict = {\"Cross-Correlation Delay (s)\" : delay,\"ID\": id, \"date\" : date,\"type\":\"F-D\"}\n",
    "        df_list.append(lag_dict)\n",
    "\n",
    "        for lag,c in zip(lags,corr):\n",
    "            graph_dict = {\"Lags (s)\" : lag,\"Cross-Correlation\": c,\"ID\": id, \"date\" : date,\"type\":\"F-D\"}\n",
    "            graph_df_list.append(graph_dict)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "lag_df = pd.DataFrame.from_dict(df_list)\n",
    "graph_df = pd.DataFrame.from_dict(graph_df_list)\n",
    "\n",
    "###generate delay bar graph\n",
    "plt.figure(figsize = (0.8,1.2))\n",
    "g = sns.barplot(data = lag_df.groupby([\"ID\",'type']).mean().reset_index(), x = \"type\", y = \"Cross-Correlation Delay (s)\",errorbar= \"se\",fill = None,errwidth= 1)\n",
    "sns.stripplot(data = lag_df.groupby([\"ID\",'type']).mean().reset_index(), x = \"type\", y = \"Cross-Correlation Delay (s)\",color = \"black\",alpha = 0.3,s = 4,jitter = 0.1)\n",
    "\n",
    "\n",
    "#g.set_yticks(np.arange(-0.5,2.5,0.5))\n",
    "#g.set(ylim=(-0.5, 3))\n",
    "g.xaxis.label.set_visible(False)\n",
    "g.set_ylabel(\"Cross-Correlation\\nDelay (s)\")\n",
    "\n",
    "#plt.savefig(rf\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Manuscripts/2023-ACCArousal-CurrentBiology/SavedGraphs/FP_dfflag_bar.pdf\",format =\"pdf\",transparent = True,bbox_inches = \"tight\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###cross correlation line graph\n",
    "\n",
    "plt.figure(figsize = (1,1.2))\n",
    "ax = sns.lineplot(data = graph_df.groupby([\"ID\",'type','Lags (s)']).mean().reset_index(), x = \"Lags (s)\", y = \"Cross-Correlation\",errorbar=\"se\",hue = \"type\",palette = [\"purple\",\"dodgerblue\",\"darkorange\"],legend=None,linewidth = 1)\n",
    "#format_ax(ax,(-3,3),(-0.5,1.5),3,1)\n",
    "ax.axvline(0,linestyle = \"dashed\", color = \"black\",alpha = 0.3)\n",
    "\n",
    "\n",
    "#plt.savefig(rf\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Manuscripts/2023-ACCArousal-CurrentBiology/SavedGraphs/FP_lag_line.pdf\",format =\"pdf\",transparent = True,bbox_inches = \"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###aligned trace all trials\n",
    "\n",
    "\n",
    "\n",
    "id_date = {\n",
    "  \"LC01\":[\"20240419\"],\n",
    "  \"LC02\":[\"20240416\"],\n",
    "  \"LC03\":[\"20240419\"],\n",
    "  \"LC04\":[\"20240416\",\"20240417\"],\n",
    "  \"LC05\":[\"20240513\"],\n",
    "  \"LC06\":[\"20240513\"],\n",
    "\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "df_list = []\n",
    "for id,dates in id_date.items():\n",
    "    for date in dates:\n",
    "      \n",
    "        events = get_pupil_events(id,date)\n",
    "        onsets = [on/20 for on in events[\"onsets\"]] ###get pupil onsets\n",
    "        onsets_ix = events[\"onsets\"]\n",
    "        print(len(events))\n",
    "  \n",
    "        path = f\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Scripts/Nithik/ACC_Arousal_Paper/LC_data/{id}_{date}_fixed.csv\"\n",
    "        df = pd.read_csv(path)\n",
    "        time = df[\"t\"]\n",
    "        pupil = np.array(zscore(df[\"pupil\"])) ###zscore pupil data\n",
    "        face = np.array(zscore(df[\"mot_whisk\"]))###zscore face data\n",
    "        dff = np.array(zscore(df[\"fp_lc\"])) ###zscore dff data\n",
    "\n",
    "\n",
    "\n",
    "        dil_matrix,dil_times = trial_align(onsets,time,pupil,fps = 20,pre = 10, post = 10 )\n",
    "        trial_matrix,trial_times = trial_align(onsets,time,dff,fps = 20,pre = 10, post = 10)\n",
    "        face_matrix,face_times = trial_align(onsets,time,face,fps = 20,pre = 10, post = 10)\n",
    "\n",
    "        for j,trial in enumerate(dil_matrix):\n",
    "            baseline = np.mean(pupil[onsets_ix[j] - 40:onsets_ix[j] - 10])\n",
    "            trial = trial - baseline\n",
    "\n",
    "            for i,Time in enumerate(dil_times):\n",
    "                new_dict = {\"Time from Onset (s)\" : Time, \"trial\" : j, \"value\" : trial[i], \"type\" : \"Pupil\",\"ID\" : id, \"Date\": date}\n",
    "                df_list.append(new_dict)\n",
    "\n",
    "        for j,trial in enumerate(trial_matrix):\n",
    "            baseline = np.mean(dff[onsets_ix[j] - 40:onsets_ix[j] - 10])\n",
    "            trial = trial - baseline\n",
    "         \n",
    "            for i,Time in enumerate(trial_times):\n",
    "                new_dict = {\"Time from Onset (s)\" : Time, \"trial\" : j, \"value\" : trial[i], \"type\" : \"dff\",\"ID\" : id, \"Date\": date}\n",
    "                df_list.append(new_dict)\n",
    "\n",
    "        for j,trial in enumerate(face_matrix):\n",
    "            baseline = np.mean(face[onsets_ix[j] - 40:onsets_ix[j] - 10])\n",
    "            trial = trial - baseline\n",
    "          \n",
    "            for i,Time in enumerate(face_times):\n",
    "                new_dict = {\"Time from Onset (s)\" : Time, \"trial\" : j, \"value\" : trial[i], \"type\" : \"Face\",\"ID\" : id, \"Date\": date}\n",
    "                df_list.append(new_dict)\n",
    "\n",
    "align_df = pd.DataFrame.from_dict(df_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,5))\n",
    "ax = sns.lineplot(data = align_df.groupby([\"ID\",\"Time from Onset (s)\",\"type\"]).mean().reset_index(), x = \"Time from Onset (s)\", y = \"value\", hue = \"type\",errorbar = \"se\",palette= [\"purple\",\"dodgerblue\",\"green\"],legend= True,linewidth = 1)\n",
    "format_ax(ax,(-1,0.5),(-0.5,2),1,0.5)\n",
    "ax.set_xlabel(\"Time from \\nDilation Onset (s)\")\n",
    "ax.set_ylabel('Z-Score')\n",
    "ax.axvline(0,linestyle = \"dashed\", color = \"black\",alpha = 0.3)\n",
    "\n",
    "\n",
    "#plt.savefig(rf\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Manuscripts/2023-ACCArousal-CurrentBiology/SavedGraphs/FP_avgdff_line.pdf\",format =\"pdf\",transparent = True,bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###align to pupil dilation onset binned by quartile\n",
    "\n",
    "\n",
    "id_date = {\n",
    "  \"LC01\":[\"20240419\"],\n",
    "  \"LC02\":[\"20240416\"],\n",
    "  \"LC03\":[\"20240419\"],\n",
    "  \"LC04\":[\"20240416\",\"20240417\"],\n",
    "  \"LC05\":[\"20240513\"],\n",
    "  \"LC06\":[\"20240513\"],\n",
    "\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "df_list = []\n",
    "for id,dates in id_date.items():\n",
    "    for date in dates:\n",
    "      \n",
    "        events = get_pupil_events(id,date)\n",
    "        onsets = [on/20 for on in events[\"onsets\"]] ###get pupil onsets\n",
    "        onsets_ix = events[\"onsets\"]\n",
    "        amplitudes = events[\"amplitudes\"]\n",
    "        binned_amps = np.array(pd.qcut(amplitudes,q = 4,labels = [1,2,3,4]))\n",
    "   \n",
    "        path = f\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Scripts/Nithik/ACC_Arousal_Paper/LC_data/{id}_{date}_fixed.csv\"\n",
    "        df = pd.read_csv(path)\n",
    "        time = df[\"t\"]\n",
    "        pupil = filter_pupil(np.array(zscore(df[\"pupil\"]))) ###zscore pupil data\n",
    "        face = np.array(zscore(df[\"mot_whisk\"]))###zscore face data\n",
    "        dff = np.array(zscore(df[\"fp_lc\"])) ###zscore dff data\n",
    "\n",
    "       \n",
    "\n",
    "        dil_matrix,dil_times = trial_align(onsets,time,pupil,fps = 20,pre = 10, post = 10 )\n",
    "        \n",
    "\n",
    "        for j,trial in enumerate(dil_matrix):\n",
    "            baseline = np.mean(pupil[onsets_ix[j] - 40:onsets_ix[j] - 10])\n",
    "            trial = trial - baseline\n",
    "            for i,Time in enumerate(dil_times):\n",
    "                new_dict = {\"Time from Onset (s)\" : Time, \"trial\" : j, \"value\" : trial[i], \"type\" : \"Pupil\",\"ID\" : id, \"Date\": date,\"amp\":amplitudes[j],\"animal_amp_bin\":binned_amps[j]}\n",
    "                df_list.append(new_dict)\n",
    "\n",
    "        trial_matrix,trial_times = trial_align(onsets,time,dff,fps = 20,pre = 10, post = 10)\n",
    "        for j,trial in enumerate(trial_matrix):\n",
    "            baseline = np.mean(dff[onsets_ix[j] - 40:onsets_ix[j] - 10])\n",
    "            trial = trial - baseline\n",
    "            for i,Time in enumerate(trial_times):\n",
    "                new_dict = {\"Time from Onset (s)\" : Time, \"trial\" : j, \"value\" : trial[i], \"type\" : \"dff\",\"ID\" : id, \"Date\": date,\"amp\":amplitudes[j],\"animal_amp_bin\":binned_amps[j]}\n",
    "                df_list.append(new_dict)\n",
    "        \n",
    "        face_matrix,face_times = trial_align(onsets,time,face,fps = 20,pre = 10, post = 10)\n",
    "        for j,trial in enumerate(face_matrix):\n",
    "            baseline = np.mean(face[onsets_ix[j] - 40:onsets_ix[j] - 10])\n",
    "            trial = trial - baseline\n",
    "            for i,Time in enumerate(face_times):\n",
    "                new_dict = {\"Time from Onset (s)\" : Time, \"trial\" : j, \"value\" : trial[i], \"type\" : \"face\",\"ID\" : id, \"Date\": date,\"amp\":amplitudes[j],\"animal_amp_bin\":binned_amps[j]}\n",
    "                df_list.append(new_dict)\n",
    "\n",
    "\n",
    "align_df = pd.DataFrame.from_dict(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###zoomed in average trace\n",
    "plt.figure(figsize = (2.7,3.2))\n",
    "ax = sns.lineplot(data = align_df.groupby([\"ID\",\"Time from Onset (s)\",\"type\",\"animal_amp_bin\"]).mean().reset_index().query(\"animal_amp_bin == 1\"), x = \"Time from Onset (s)\", y = \"value\", hue = \"type\",errorbar = \"se\",palette= [\"dodgerblue\",\"green\",\"purple\"],legend= None,linewidth = 1)\n",
    "format_ax(ax,(-1.5,0.5),(-0.5,2),0.5,0.25)\n",
    "ax.set_xlabel(\"Time from \\ndilation onset (s)\")\n",
    "ax.set_ylabel('Z-Score')\n",
    "\n",
    "ax.axvline(0,linestyle = \"dashed\", color = \"black\",linewidth = 0.5)\n",
    "\n",
    "#plt.savefig(rf\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Manuscripts/2023-ACCArousal-CurrentBiology/SavedGraphs/FP_avgdffzoom_line.pdf\",format =\"pdf\",transparent = True,bbox_inches = \"tight\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###plot different quartiles of pupil aligned to pupil onset\n",
    "plt.figure(figsize = (5,5))\n",
    "ax = sns.lineplot(data = align_df.groupby([\"ID\",\"Time from Onset (s)\",\"type\",\"animal_amp_bin\"]).mean().reset_index().query(\"animal_amp_bin == 1\"), x = \"Time from Onset (s)\", y = \"value\",errorbar = \"se\",hue = \"type\",legend = True,linewidth = 1)\n",
    "#ax.set_xlabel(\"Time from \\nDilation Onset (s)\")\n",
    "ax.xaxis.label.set_visible(False)\n",
    "\n",
    "ax.set_ylabel(\"Pupil Size \\n(z-scr)\")\n",
    "ax.axvline(0,linestyle = \"dashed\", color = \"black\",linewidth = 0.5)\n",
    "format_ax(ax,(-1.5,10),(-0.5,3),0.5,0.5)\n",
    "#plt.savefig(rf\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Manuscripts/2023-ACCArousal-CurrentBiology/SavedGraphs/FP_pupil_quartile_line.pdf\",format =\"pdf\",transparent = True,bbox_inches = \"tight\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###plot different quartiles of pupil aligned to pupil onset\n",
    "plt.figure(figsize = (5,5))\n",
    "ax = sns.lineplot(data = align_df.groupby([\"ID\",\"Time from Onset (s)\",\"type\",\"animal_amp_bin\"]).mean().reset_index().query(\"animal_amp_bin == 3\"), x = \"Time from Onset (s)\", y = \"value\",errorbar = \"se\",hue = \"type\",legend = True,linewidth = 1)\n",
    "#ax.set_xlabel(\"Time from \\nDilation Onset (s)\")\n",
    "ax.xaxis.label.set_visible(False)\n",
    "\n",
    "ax.set_ylabel(\"Pupil Size \\n(z-scr)\")\n",
    "ax.axvline(0,linestyle = \"dashed\", color = \"black\",linewidth = 0.5)\n",
    "format_ax(ax,(-2/.5,10),(-0.5,3),0.5,0.5)\n",
    "#plt.savefig(rf\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Manuscripts/2023-ACCArousal-CurrentBiology/SavedGraphs/FP_pupil_quartile_line.pdf\",format =\"pdf\",transparent = True,bbox_inches = \"tight\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###plot different quartiles of pupil aligned to pupil onset\n",
    "plt.figure(figsize = (3.25,3))\n",
    "ax = sns.lineplot(data = align_df.groupby([\"ID\",\"Time from Onset (s)\",\"type\",\"animal_amp_bin\"]).mean().reset_index().query(\"type == 'Pupil'\"), x = \"Time from Onset (s)\", y = \"value\",errorbar = \"se\",hue = \"animal_amp_bin\",legend = None,linewidth = 1)\n",
    "#ax.set_xlabel(\"Time from \\nDilation Onset (s)\")\n",
    "ax.xaxis.label.set_visible(False)\n",
    "\n",
    "ax.set_ylabel(\"Pupil Size \\n(z-scr)\")\n",
    "ax.axvline(0,linestyle = \"dashed\", color = \"black\",linewidth = 0.5)\n",
    "format_ax(ax,(-2,3.5),(-0.5,3),0.5,0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###plot different quartiles of pupil aligned to pupil onset\n",
    "plt.figure(figsize = (3.25,3))\n",
    "ax = sns.lineplot(data = align_df.groupby([\"ID\",\"Time from Onset (s)\",\"type\",\"animal_amp_bin\"]).mean().reset_index().query(\"type == 'face'\"), x = \"Time from Onset (s)\", y = \"value\",errorbar = \"se\",hue = \"animal_amp_bin\",legend = None,linewidth = 1)\n",
    "#ax.set_xlabel(\"Time from \\nDilation Onset (s)\")\n",
    "ax.xaxis.label.set_visible(False)\n",
    "\n",
    "ax.set_ylabel(\"Pupil Size \\n(z-scr)\")\n",
    "ax.axvline(0,linestyle = \"dashed\", color = \"black\",linewidth = 0.5)\n",
    "format_ax(ax,(-2,3.5),(-0.5,3),0.5,0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###plot different quartiles of pupil aligned to pupil onset\n",
    "plt.figure(figsize = (3.25,3))\n",
    "ax = sns.lineplot(data = align_df.groupby([\"ID\",\"Time from Onset (s)\",\"type\",\"animal_amp_bin\"]).mean().reset_index().query(\"type == 'dff'\"), x = \"Time from Onset (s)\", y = \"value\",errorbar = \"se\",hue = \"animal_amp_bin\",legend = None,linewidth = 1)\n",
    "\n",
    "#ax.set_xlabel(\"Time from \\nDilation Onset (s)\")\n",
    "ax.xaxis.label.set_visible(False)\n",
    "\n",
    "ax.set_ylabel(\"Pupil Size \\n(z-scr)\")\n",
    "ax.axvline(0,linestyle = \"dashed\", color = \"black\",linewidth = 0.5)\n",
    "format_ax(ax,(-2,3.5),(-0.5,3),0.5,0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###plot different quartiles of pupil aligned to pupil onset\n",
    "plt.figure(figsize = (1.25,1))\n",
    "ax = sns.lineplot(data = align_df.groupby([\"ID\",\"Time from Onset (s)\",\"type\",\"animal_amp_bin\"]).mean().reset_index().query(\"type == 'Pupil'\").query(\"animal_amp_bin == [1,4]\"), x = \"Time from Onset (s)\", y = \"value\",errorbar = \"se\",hue = \"animal_amp_bin\",palette= [\"cornflowerblue\",\"darkblue\"],legend = None,linewidth = 1)\n",
    "\n",
    "#ax.set_xlabel(\"Time from \\nDilation Onset (s)\")\n",
    "ax.xaxis.label.set_visible(False)\n",
    "ax.set_ylabel(\"Pupil Size \\n(z-scr)\")\n",
    "ax.axvline(0,linestyle = \"dashed\", color = \"black\",linewidth = 0.5)\n",
    "format_ax(ax,(-0.5,0.5),(-0.5,4),0.5,0.5)\n",
    "plt.savefig(rf\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Manuscripts/2023-ACCArousal-CurrentBiology/SavedGraphs/LC_pupil_quartile_line.pdf\",format =\"pdf\",transparent = True,bbox_inches = \"tight\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###plot different quartiles of pupil aligned to pupil onset\n",
    "plt.figure(figsize = (1.25,1.25))\n",
    "ax = sns.lineplot(data = align_df.groupby([\"ID\",\"Time from Onset (s)\",\"type\",\"animal_amp_bin\"]).mean().reset_index().query(\"type == 'dff'\").query(\"animal_amp_bin == [1,4]\"), x = \"Time from Onset (s)\", y = \"value\",errorbar = \"se\",hue = \"animal_amp_bin\",palette= [\"palegreen\",\"darkgreen\"],legend = None,linewidth = 1)\n",
    "ax.set_xlabel(\"Time from \\nDilation Onset (s)\")\n",
    "ax.set_ylabel(\"∆ F/F (z-scr)\")\n",
    "ax.axvline(0,linestyle = \"dashed\", color = \"black\",linewidth = 0.5)\n",
    "format_ax(ax,(-0.5,0.5),(-0.5,2),0.5,0.5)\n",
    "plt.savefig(rf\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Manuscripts/2023-ACCArousal-CurrentBiology/SavedGraphs/LC_dff_quartile_line.pdf\",format =\"pdf\",transparent = True,bbox_inches = \"tight\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###align to pupil dilation peak binned by quartile\n",
    "\n",
    "id_date = {\n",
    "  \"LC01\":[\"20240419\"],\n",
    "  \"LC02\":[\"20240416\"],\n",
    "  \"LC03\":[\"20240419\"],\n",
    "  \"LC04\":[\"20240416\",\"20240417\"],\n",
    "  \"LC05\":[\"20240513\"],\n",
    "  \"LC06\":[\"20240513\"],\n",
    "\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "df_list = []\n",
    "for id,dates in id_date.items():\n",
    "    for date in dates:\n",
    "      \n",
    "        events = get_pupil_events(id,date)\n",
    "        peaks = [on/20 for on in events[\"peak_ix\"]] ### get pupil peaks\n",
    "        onsets_ix = events[\"onsets\"]\n",
    "        amplitudes = events[\"amplitudes\"]\n",
    "        binned_amps = np.array(pd.qcut(amplitudes,q = 4,labels = [1,2,3,4]))\n",
    "   \n",
    "        path = f\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Scripts/Nithik/ACC_Arousal_Paper/LC_data/{id}_{date}_fixed.csv\"\n",
    "        df = pd.read_csv(path)\n",
    "        time = df[\"t\"]\n",
    "        pupil = filter_pupil(np.array(zscore(df[\"pupil\"]))) ###zscore pupil data\n",
    "        face = np.array(zscore(df[\"mot_whisk\"]))###zscore face data\n",
    "        dff = np.array(zscore(df[\"fp_lc\"])) ###zscore dff data\n",
    "\n",
    "       \n",
    "\n",
    "        dil_matrix,dil_times = trial_align(peaks,time,pupil,fps = 20,pre = 10, post = 10 )\n",
    "\n",
    "        for j,trial in enumerate(dil_matrix):\n",
    "            baseline = np.mean(pupil[onsets_ix[j] - 40:onsets_ix[j] - 10])\n",
    "            trial = trial - baseline\n",
    "            for i,Time in enumerate(dil_times):\n",
    "                new_dict = {\"Time from Onset (s)\" : Time, \"trial\" : j, \"value\" : trial[i], \"type\" : \"Pupil\",\"ID\" : id, \"Date\": date,\"amp\":amplitudes[j],\"animal_amp_bin\":binned_amps[j]}\n",
    "                df_list.append(new_dict)\n",
    "\n",
    "        trial_matrix,trial_times = trial_align(peaks,time,dff,fps = 20,pre = 10, post = 10)\n",
    "        for j,trial in enumerate(trial_matrix):\n",
    "            baseline = np.mean(dff[onsets_ix[j] - 40:onsets_ix[j] - 10])\n",
    "            trial = trial - baseline\n",
    "            for i,Time in enumerate(trial_times):\n",
    "                new_dict = {\"Time from Onset (s)\" : Time, \"trial\" : j, \"value\" : trial[i], \"type\" : \"dff\",\"ID\" : id, \"Date\": date,\"amp\":amplitudes[j],\"animal_amp_bin\":binned_amps[j]}\n",
    "                df_list.append(new_dict)\n",
    "\n",
    "align_df = pd.DataFrame.from_dict(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###plot different quartiles of pupil aligned to pupil onset\n",
    "plt.figure(figsize = (5,5))\n",
    "ax = sns.lineplot(data = align_df.groupby([\"ID\",\"Time from Onset (s)\",\"type\",\"animal_amp_bin\"]).mean().reset_index().query(\"type == 'dff'\"), x = \"Time from Onset (s)\", y = \"value\",errorbar = \"se\",hue = \"animal_amp_bin\",legend = True,linewidth = 1)\n",
    "ax.set_xlabel(\"Time from \\nDilation Onset (s)\")\n",
    "ax.set_ylabel(\"∆ F/F (z-scr)\")\n",
    "ax.axvline(0,linestyle = \"dashed\", color = \"black\",linewidth = 0.5)\n",
    "format_ax(ax,(-0.5,3.5),(-0.5,3),0.5,0.5)\n",
    "#plt.savefig(rf\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Manuscripts/2023-ACCArousal-CurrentBiology/SavedGraphs/FP_dff_quartile_line.pdf\",format =\"pdf\",transparent = True,bbox_inches = \"tight\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###plot different quartiles of pupil aligned to pupil peak\n",
    "plt.figure(figsize = (1.25,1))\n",
    "ax = sns.lineplot(data = align_df.groupby([\"ID\",\"Time from Onset (s)\",\"type\",\"animal_amp_bin\"]).mean().reset_index().query(\"type == 'Pupil'\").query(\"animal_amp_bin == [1,4]\"), x = \"Time from Onset (s)\", y = \"value\",errorbar = \"se\",hue = \"animal_amp_bin\",palette= [\"cornflowerblue\",\"darkblue\"],legend = None,linewidth = 1)\n",
    "#ax.set_xlabel(\"Time from \\nDilation Peak (s)\")\n",
    "ax.xaxis.label.set_visible(False)\n",
    "\n",
    "ax.set_ylabel(\"Pupil Size \\n(z-scr)\")\n",
    "ax.axvline(0,linestyle = \"dashed\", color = \"black\",linewidth = 0.5)\n",
    "format_ax(ax,(-0.5,1),(-0.5,4),0.5,0.5)\n",
    "ax.spines[['left']].set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "plt.savefig(rf\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Manuscripts/2023-ACCArousal-CurrentBiology/SavedGraphs/LC_pupil_peakquartile_line.pdf\",format =\"pdf\",transparent = True,bbox_inches = \"tight\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.relplot(data = align_df.query(\"type == 'Pupil'\").query(\"animal_amp_bin == [1,4]\"), x = \"Time from Onset (s)\", y = \"value\",errorbar = \"se\",hue = \"animal_amp_bin\",palette= [\"cornflowerblue\",\"darkblue\"],legend = None,linewidth = 1,kind = \"line\",col = \"ID\")\n",
    "for ax in ax.axes[0]:\n",
    "    ax.axvline(0,linestyle = \"dashed\", color = \"black\",linewidth = 0.5)\n",
    "    format_ax(ax,(-0.5,1),(-0.5,4),0.5,0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###plot different quartiles of pupil aligned to pupil peak\n",
    "plt.figure(figsize = (1.25,1.25))\n",
    "ax = sns.lineplot(data = align_df.groupby([\"ID\",\"Time from Onset (s)\",\"type\",\"animal_amp_bin\"]).mean().reset_index().query(\"type == 'dff'\").query(\"animal_amp_bin == [1,4]\"), x = \"Time from Onset (s)\", y = \"value\",errorbar = \"se\",hue = \"animal_amp_bin\",palette= [\"palegreen\",\"darkgreen\"],legend = None,linewidth = 1)\n",
    "ax.set_xlabel(\"Time from \\nDilation Peak (s)\")\n",
    "ax.set_ylabel(\"∆ F/F (z-scr)\")\n",
    "ax.axvline(0,linestyle = \"dashed\", color = \"black\",linewidth = 0.5)\n",
    "format_ax(ax,(-0.5,1),(-0.5,2),0.5,0.5)\n",
    "ax.spines[['left']].set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "plt.savefig(rf\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Manuscripts/2023-ACCArousal-CurrentBiology/SavedGraphs/LC_dff_peakquartile_line.pdf\",format =\"pdf\",transparent = True,bbox_inches = \"tight\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### mean dff within amplitude quartiles\n",
    "\n",
    "id_date = {\n",
    "  \"LC01\":[\"20240419\"],\n",
    "  \"LC02\":[\"20240416\"],\n",
    "  \"LC03\":[\"20240419\"],\n",
    "  \"LC04\":[\"20240416\",\"20240417\"],\n",
    "  \"LC05\":[\"20240513\"],\n",
    "  \"LC06\":[\"20240513\"],\n",
    "\n",
    "\n",
    "\n",
    "}\n",
    "labels = [\"1\",\"2\",\"3\",\"4\"]\n",
    "df_list = []\n",
    "for id,dates in id_date.items():\n",
    "    for date in dates:\n",
    "      \n",
    "        events = get_pupil_events(id,date)\n",
    "        peak_ix = events[\"peak_ix\"]\n",
    "        onsets = [on for on in events[\"onsets\"]] ###get pupil onsets ix\n",
    "        onsets_ix = events[\"onsets\"]\n",
    "        offsets = [off for off in events[\"offsets\"]] ###get pupil offsets ix\n",
    "        amplitudes = events[\"amplitudes\"]\n",
    "        binned_amps = np.array(pd.qcut(amplitudes,q = 4,labels = labels))\n",
    "     \n",
    "\n",
    "  \n",
    "        path = f\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Scripts/Nithik/ACC_Arousal_Paper/LC_data/{id}_{date}_fixed.csv\"\n",
    "        df = pd.read_csv(path)\n",
    "        time = df[\"t\"]\n",
    "        pupil = np.array(zscore(df[\"pupil\"])) ###zscore pupil data\n",
    "        face = np.array(zscore(df[\"mot_whisk\"]))###zscore face data\n",
    "        dff = np.array(zscore(df[\"fp_lc\"])) ###zscore dff data\n",
    "\n",
    "       \n",
    "\n",
    "     \n",
    "        for i,(on,off) in enumerate(zip(onsets,offsets)):\n",
    "          baseline = np.mean(dff[on - 40:on - 10])\n",
    "          pre_dff =np.mean(dff[on-5:on]) - baseline\n",
    "          during_dff = np.mean(dff[on:off]) - baseline\n",
    "\n",
    "\n",
    "          new_dict = { \"trial\" : i,\"ID\" : id, \"Date\": date,\"amp\":amplitudes[i],\"animal_amp_bin\":binned_amps[i],\"Pre Onset ∆ F/F\":pre_dff,\"∆ F/F\": during_dff}\n",
    "          df_list.append(new_dict)\n",
    "\n",
    "\n",
    "bar_df = pd.DataFrame.from_dict(df_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (1,1.25))\n",
    "g = sns.barplot(data = bar_df.groupby([\"ID\",'animal_amp_bin']).mean().reset_index(), x = \"animal_amp_bin\", y = \"Pre Onset ∆ F/F\",errorbar = \"se\",fill = None,errwidth= 1)\n",
    "sns.lineplot(data = bar_df.groupby([\"ID\",'animal_amp_bin']).mean().reset_index(), x = \"animal_amp_bin\", y = \"Pre Onset ∆ F/F\",units = \"ID\",estimator = None,color = \"black\",alpha = 0.3,linewidth = 0.5)\n",
    "\n",
    "# g.set_xlabel(\"Dilation amplitude\\n quartile\")\n",
    "# g.set_yticks(np.arange(0,2.5,0.5))\n",
    "# g.set(ylim=(0,2))\n",
    "#plt.savefig(rf\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Manuscripts/2023-ACCArousal-CurrentBiology/SavedGraphs/LC_ampbin_predff_bar.pdf\",format =\"pdf\",transparent = True,bbox_inches = \"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###stats\n",
    "q1 = bar_df.groupby([\"ID\",'animal_amp_bin']).mean().reset_index().query(\"animal_amp_bin == '1'\")[\"Pre Onset ∆ F/F\"]\n",
    "q2 = bar_df.groupby([\"ID\",'animal_amp_bin']).mean().reset_index().query(\"animal_amp_bin == '2'\")[\"Pre Onset ∆ F/F\"]\n",
    "q3 = bar_df.groupby([\"ID\",'animal_amp_bin']).mean().reset_index().query(\"animal_amp_bin == '3'\")[\"Pre Onset ∆ F/F\"]\n",
    "q4 = bar_df.groupby([\"ID\",'animal_amp_bin']).mean().reset_index().query(\"animal_amp_bin == '4'\")[\"Pre Onset ∆ F/F\"]\n",
    "kruskal(q1,q2,q3,q4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (1,1.25))\n",
    "g = sns.barplot(data = bar_df.groupby([\"ID\",'animal_amp_bin']).mean().reset_index(), x = \"animal_amp_bin\", y = \"∆ F/F\",errorbar = \"se\",fill = None,errwidth= 1)\n",
    "sns.lineplot(data = bar_df.groupby([\"ID\",'animal_amp_bin']).mean().reset_index(), x = \"animal_amp_bin\", y = \"∆ F/F\",units = \"ID\",estimator = None,color = \"black\",alpha = 0.3,linewidth = 0.5)\n",
    "\n",
    "g.set_xlabel(\"Dilation amplitude\\n quartile\")\n",
    "g.set_ylabel(\"Peri-event ∆F/F\")\n",
    "\n",
    "g.set_yticks(np.arange(0,0.75,0.25))\n",
    "g.set(ylim=(0,0.5))\n",
    "#plt.savefig(rf\"/Users/nithik/Library/CloudStorage/Box-Box/HUDA_LAB_DATA/Manuscripts/2023-ACCArousal-CurrentBiology/SavedGraphs/LC_ampbin_dff_bar.pdf\",format =\"pdf\",transparent = True,bbox_inches = \"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###stats\n",
    "q1 = bar_df.groupby([\"ID\",'animal_amp_bin']).mean().reset_index().query(\"animal_amp_bin == '1'\")[\"∆ F/F\"]\n",
    "q2 = bar_df.groupby([\"ID\",'animal_amp_bin']).mean().reset_index().query(\"animal_amp_bin == '2'\")[\"∆ F/F\"]\n",
    "q3 = bar_df.groupby([\"ID\",'animal_amp_bin']).mean().reset_index().query(\"animal_amp_bin == '3'\")[\"∆ F/F\"]\n",
    "q4 = bar_df.groupby([\"ID\",'animal_amp_bin']).mean().reset_index().query(\"animal_amp_bin == '4'\")[\"∆ F/F\"]\n",
    "kruskal(q1,q2,q3,q4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HudaLab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
